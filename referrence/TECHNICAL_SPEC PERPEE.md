# Perpee - Technical Specification

**Version:** 1.0  
**Last Updated:** January 6, 2025  
**Status:** Ready for Implementation  
**Related Document:** PRD.md

---

## Overview

This document contains the complete technical specification for implementing Perpee, an AI-powered price monitoring agent. It is designed for use with Claude Code for AI-assisted implementation.

### Document Structure

| Section | Description |
|---------|-------------|
| Architecture | System diagram, tech stack, data flow |
| Component 1 | Project Structure & Agent Core |
| Component 2 | Database Schema & Models |
| Component 3 | Scraper Engine |
| Component 4 | RAG System |
| Component 5 | Self-Healing Module |
| Component 6 | Scheduler |
| Component 7 | Notifications |
| Component 8 | API Endpoints |
| Component 9 | Web UI |
| Appendices | Store list, costs, dependencies |

---

## Technical Architecture

### System Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Docker Container                          â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                      FastAPI Server                       â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚   Agent     â”‚  â”‚   Scraper   â”‚  â”‚    Scheduler    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  (Pydantic  â”‚  â”‚  (Crawl4AI) â”‚  â”‚  (APScheduler)  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚    AI)      â”‚  â”‚             â”‚  â”‚                 â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚         â”‚                â”‚                  â”‚           â”‚   â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚   â”‚
â”‚  â”‚                          â”‚                              â”‚   â”‚
â”‚  â”‚                    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                        â”‚   â”‚
â”‚  â”‚                    â”‚  SQLite   â”‚                        â”‚   â”‚
â”‚  â”‚                    â”‚ + ChromaDBâ”‚                        â”‚   â”‚
â”‚  â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚    RAG      â”‚  â”‚ Self-Heal   â”‚  â”‚  Notifications  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  (ChromaDB) â”‚  â”‚   Module    â”‚  â”‚    (Resend)     â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚              Static Frontend (React)              â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                    â”‚                    â”‚
         â–¼                    â–¼                    â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚OpenRouterâ”‚        â”‚Retailer â”‚         â”‚ Resend  â”‚
    â”‚  (LLM)  â”‚         â”‚ Sites   â”‚         â”‚ (Email) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tech Stack

| Layer | Technology | Purpose |
|-------|------------|---------|
| **Backend** | Python 3.11+, FastAPI | API server, async support |
| **Agent** | Pydantic AI | LLM agent framework |
| **Database** | SQLite + SQLModel | Relational data, ORM |
| **Vector DB** | ChromaDB | Semantic product search |
| **Scraping** | Crawl4AI (Playwright) | Web scraping with stealth |
| **LLM** | OpenRouter | Model routing, fallbacks |
| **Frontend** | Vite + React | SPA, fast builds |
| **UI Components** | shadcn/ui + Tailwind | Accessible, customizable |
| **Email** | Resend | Transactional email |
| **Scheduler** | APScheduler | Cron jobs, persistence |
| **Infrastructure** | Docker | Single container deployment |
| **Hosting** | Oracle Cloud Free Tier | Free VM (1GB RAM) |

### Data Flow

```
User Input (Chat/URL)
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Agent Core    â”‚ â”€â”€â”€â”€ Decides action via LLM
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼         â–¼             â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Scrape â”‚ â”‚ Query â”‚   â”‚ Schedule â”‚   â”‚  Alert   â”‚
â”‚Productâ”‚ â”‚  RAG  â”‚   â”‚   Job    â”‚   â”‚  Setup   â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
    â”‚         â”‚            â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚   SQLite   â”‚
             â”‚  Database  â”‚
             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Price Change?   â”‚
          â”‚ Alert Trigger?  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ Yes
                   â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  Email Alert    â”‚
          â”‚    (Resend)     â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Component Specifications

## Component 1: Project Structure & Agent Core

### 1.1 Project Structure

  

```

perpee/

â”œâ”€â”€ docker/

â”‚ Â  â”œâ”€â”€ Dockerfile

â”‚ Â  â””â”€â”€ docker-compose.yml

â”‚

â”œâ”€â”€ data/ Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Mounted volume (persisted)

â”‚ Â  â”œâ”€â”€ perpee.db Â  Â  Â  Â  Â  Â  Â  # SQLite database

â”‚ Â  â”œâ”€â”€ chromadb/ Â  Â  Â  Â  Â  Â  Â  # Vector embeddings

â”‚ Â  â””â”€â”€ logs/ Â  Â  Â  Â  Â  Â  Â  Â  Â  # Application logs

â”‚

â”œâ”€â”€ backend/

â”‚ Â  â”œâ”€â”€ src/

â”‚ Â  â”‚ Â  â”œâ”€â”€ core/ Â  Â  Â  Â  Â  Â  Â  # Shared domain logic

â”‚ Â  â”‚ Â  â”‚ Â  â”œâ”€â”€ __init__.py

â”‚ Â  â”‚ Â  â”‚ Â  â”œâ”€â”€ exceptions.py Â  # Custom exceptions

â”‚ Â  â”‚ Â  â”‚ Â  â”œâ”€â”€ constants.py Â  Â # App-wide constants

â”‚ Â  â”‚ Â  â”‚ Â  â””â”€â”€ security.py Â  Â  # URL validation, sanitization

â”‚ Â  â”‚ Â  â”œâ”€â”€ agent/ Â  Â  Â  Â  Â  Â  Â # Pydantic AI agent

â”‚ Â  â”‚ Â  â”œâ”€â”€ scraper/ Â  Â  Â  Â  Â  Â # Crawl4AI & extraction

â”‚ Â  â”‚ Â  â”œâ”€â”€ rag/ Â  Â  Â  Â  Â  Â  Â  Â # ChromaDB & embeddings

â”‚ Â  â”‚ Â  â”œâ”€â”€ scheduler/ Â  Â  Â  Â  Â # APScheduler jobs

â”‚ Â  â”‚ Â  â”œâ”€â”€ notifications/ Â  Â  Â # Email notifications

â”‚ Â  â”‚ Â  â”œâ”€â”€ api/ Â  Â  Â  Â  Â  Â  Â  Â # FastAPI endpoints

â”‚ Â  â”‚ Â  â”œâ”€â”€ database/ Â  Â  Â  Â  Â  # SQLModel models

â”‚ Â  â”‚ Â  â””â”€â”€ utils/ Â  Â  Â  Â  Â  Â  Â # Generic helpers

â”‚ Â  â”œâ”€â”€ config/

â”‚ Â  â”‚ Â  â”œâ”€â”€ settings.py Â  Â  Â  Â  # Pydantic Settings

â”‚ Â  â”‚ Â  â”œâ”€â”€ stores_seed.py Â  Â  Â # Initial store data for DB seeding

â”‚ Â  â”‚ Â  â””â”€â”€ prompts/ Â  Â  Â  Â  Â  Â # LLM prompt templates

â”‚ Â  â”œâ”€â”€ alembic/

â”‚ Â  â”‚ Â  â”œâ”€â”€ versions/ Â  Â  Â  Â  Â  # Migration files

â”‚ Â  â”‚ Â  â””â”€â”€ env.py

â”‚ Â  â”œâ”€â”€ alembic.ini

â”‚ Â  â”œâ”€â”€ tests/

â”‚ Â  â”œâ”€â”€ pyproject.toml Â  Â  Â # Dependencies (uv)

â”‚ Â  â””â”€â”€ uv.lock Â  Â  Â  Â  Â  Â  # Lockfile (auto-generated)

â”‚

â”œâ”€â”€ frontend/

â”‚ Â  â”œâ”€â”€ src/

â”‚ Â  â”‚ Â  â”œâ”€â”€ components/

â”‚ Â  â”‚ Â  â”œâ”€â”€ pages/

â”‚ Â  â”‚ Â  â”œâ”€â”€ hooks/

â”‚ Â  â”‚ Â  â”œâ”€â”€ lib/ Â  Â  Â  Â  Â  Â  Â  Â # API client, utils

â”‚ Â  â”‚ Â  â””â”€â”€ App.tsx

â”‚ Â  â”œâ”€â”€ public/

â”‚ Â  â”œâ”€â”€ index.html

â”‚ Â  â”œâ”€â”€ package.json

â”‚ Â  â”œâ”€â”€ vite.config.ts

â”‚ Â  â””â”€â”€ tailwind.config.js

â”‚

â”œâ”€â”€ .env.example

â”œâ”€â”€ .gitignore

â””â”€â”€ README.md

```

  

### 1.2 Infrastructure Decisions

  

| Decision | Choice | Rationale |

|----------|--------|-----------|

| Package manager | `uv` | 10-100x faster installs, automatic lockfile |

| Backend framework | FastAPI | Async, fast, great OpenAPI docs |

| Frontend framework | Vite + React (SPA) | Fast dev, simple deployment |

| Hosting model | Single Docker container | FastAPI serves static build |

| Configuration | `.env` + Pydantic Settings | Type-safe, validation built-in |

| Authentication | None (MVP) | Single user |

| Repository | Monorepo | Simpler for solo dev |

  

### 1.3 Agent Core Configuration

  

| Setting | Value | Notes |

|---------|-------|-------|

| Agent framework | Pydantic AI | Type-safe, FastAPI-native |

| Agent pattern | Hybrid (Router + ReAct) | Router for simple tasks, ReAct for complex |

| LLM provider | OpenRouter | Model switching, unified API |

| Primary model | `google/gemini-2.0-flash-exp:free` | Free, fast, 1M context |

| Fallback model 1 | `meta-llama/llama-3.3-70b-instruct:free` | Free, stable, battle-tested |

| Fallback model 2 | `anthropic/claude-3.5-haiku` | Paid, high reliability last resort |

| Conversation memory | Window-based, last 15 messages | Session-only (not persisted to DB) |

| Welcome message | Shown at chat start | Informs user that chat is session-only |

  

#### Chat Welcome Message

  

When a chat session begins, display this message (or similar):

  

```

ğŸ‘‹ Hi! I'm Perpee, your price monitoring assistant.

  

I can help you:

â€¢ Track product prices from Canadian retailers

â€¢ Set alerts when prices drop

â€¢ Compare prices across stores

  

â„¹ï¸ Note: Chat history is not saved between sessions.

Â  Â Your tracked products, alerts, and schedules are always saved.

  

Paste a product URL or ask me anything!
```

  

### 1.4 Agent Tools

| Tool | Purpose | Input | Output |
|------|---------|-------|--------|
| `scrape_product` | Extract product data from URL | `url: str` | `Product` object |
| `scan_website` | Analyze a website's structure for safe extraction before whitelisting | `url: str` | `ScanResult` (feasible, selectors, risks) |
| `search_products` | Search tracked products in local DB (not store websites) | `query: str, store?: str` | `list[Product]` |
| `web_search` | DuckDuckGo search for product URLs (shopping queries only) | `query: str` | `list[SearchResult]` |
| `get_price_history` | Query price history | `product_id: UUID, days?: int` | `list[PricePoint]` |
| `create_schedule` | Set up monitoring schedule | `product_id: UUID, cron: str` | `Schedule` |
| `set_alert` | Configure price alert | `product_id: UUID, target_price?: float, percent_drop?: int` | `Alert` |
| `compare_prices` | Cross-store comparison | `canonical_id: UUID` | `list[StorePrice]` |
| `list_products` | List tracked products | `store?: str, limit?: int` | `list[Product]` |
| `remove_product` | Stop tracking a product | `product_id: UUID` | `bool` |

  

### 1.5 Agent Guardrails

  

| Category | Guardrail | Rule | Implementation |

|----------|-----------|------|----------------|

| **Rate Limiting** | Scrape rate | Max 10 scrapes per minute | In-memory counter + queue |

| **Rate Limiting** | LLM requests | Max 30 requests per minute | Token bucket |

| **Security** | URL whitelist | Pre-configured popular Canadian stores | Domain extraction + lookup |
| **Security** | Unknown URLs | Require `scan_website` tool before adding new stores | Block until scanned |
| **Security** | SSRF protection | Block private IPs, metadata endpoints | IP validation after DNS resolution |

| **Security** | Input sanitization | Separate user content from prompts | Structured prompt templates |

| **Cost Control** | Input tokens | Max 4,000 per request | Truncation |

| **Cost Control** | Output tokens | Max 1,000 per request | Model parameter |

| **Cost Control** | Daily limit | Max 100,000 tokens/day | Hard stop with user notification |

| **Timeouts** | Request timeout | 30 seconds per HTTP request | `httpx` timeout |

| **Timeouts** | Operation timeout | 2 minutes per agent action | Asyncio timeout |

| **Behavior** | Scope limits | Product/price queries only | System prompt + output validation |

| **Behavior** | Hallucination prevention | Only report data from DB/scrape | Grounding in retrieved data |
| **Behavior** | Action confirmation | Confirm destructive actions | User confirmation for delete/bulk ops |
| **Behavior** | Web search filter | Shopping-related queries only | Query classification |
| **Behavior** | Scan website validation | Validate site safety before whitelisting | Security checks + structure analysis |

### 1.6 Configuration Files

  

#### `.env.example`

  

```env

# LLM

OPENROUTER_API_KEY=sk-or-...

PRIMARY_MODEL=google/gemini-2.0-flash-exp:free

FALLBACK_MODEL_1=meta-llama/llama-3.3-70b-instruct:free

FALLBACK_MODEL_2=anthropic/claude-3.5-haiku

  

# Embeddings

OPENAI_API_KEY=sk-...

  

# Notifications
RESEND_API_KEY=re_...
USER_EMAIL=user@example.com

# App

LOG_LEVEL=INFO

DEBUG=false

DAILY_TOKEN_LIMIT=100000

```

  

#### `pyproject.toml`

  

```toml

[project]

name = "perpee"

version = "0.1.0"

description = "AI-powered price monitoring agent for Canadian retailers"

requires-python = ">=3.11"

dependencies = [

Â  Â  "fastapi>=0.109.0",

Â  Â  "uvicorn[standard]>=0.27.0",

Â  Â  "sqlmodel>=0.0.14",

Â  Â  "alembic>=1.13.0",

Â  Â  "pydantic-settings>=2.1.0",

Â  Â  "pydantic-ai>=0.1.0",

Â  Â  "crawl4ai>=0.2.0",

Â  Â  "chromadb>=0.4.0",

Â  Â  "apscheduler>=3.10.0",

Â  Â  "httpx>=0.26.0",

Â  Â  "openai>=1.10.0",

Â  Â  "resend>=0.8.0",

Â  Â  "duckduckgo-search>=4.1.0",

Â  Â  "pyyaml>=6.0.0",

]

  

[tool.uv]

dev-dependencies = [

Â  Â  "pytest>=7.4.0",

Â  Â  "pytest-asyncio>=0.23.0",

Â  Â  "ruff>=0.1.0",

]

```

  

#### `config/settings.py` (Structure)

  

```python

from pydantic_settings import BaseSettings

  

class Settings(BaseSettings):

Â  Â  # LLM

Â  Â  openrouter_api_key: str

Â  Â  primary_model: str = "google/gemini-2.0-flash-exp:free"

Â  Â  fallback_model_1: str = "meta-llama/llama-3.3-70b-instruct:free"

Â  Â  fallback_model_2: str = "anthropic/claude-3.5-haiku"

Â  Â  # Cost controls

Â  Â  max_input_tokens: int = 4000

Â  Â  max_output_tokens: int = 1000

Â  Â  daily_token_limit: int = 100000

Â  Â  # Rate limits

Â  Â  max_scrapes_per_minute: int = 10

Â  Â  request_timeout_seconds: int = 30

Â  Â  operation_timeout_seconds: int = 120

Â  Â  # Paths

Â  Â  data_dir: str = "/app/data"

Â  Â  db_path: str = "/app/data/perpee.db"

Â  Â  class Config:

Â  Â  Â  Â  env_file = ".env"

```

  

### 1.7 Agent Personality & System Prompt

  

#### Identity

  

| Attribute | Value |

|-----------|-------|

| **Name** | Perpee |

| **Role** | AI price monitoring assistant |

| **Scope** | Canadian retail price tracking only |

| **Creator** | (Your name/brand) |

  

#### Personality Traits

  

| Trait | Description |

|-------|-------------|

| **Tone** | Friendly, helpful, and concise |

| **Style** | Conversational but efficient - gets to the point |

| **Emoji Use** | Sparingly - for price drops ğŸ“‰, alerts ğŸ””, success âœ…, errors âš ï¸ |

| **Verbosity** | Brief responses unless user asks for details |

| **Proactivity** | Suggests related actions (e.g., "Want me to set an alert?") |

| **Honesty** | Admits limitations, doesn't make up data |

  

#### Behavioral Guidelines

  

| Scenario | Behavior |

|----------|----------|

| **On-topic request** | Execute immediately, confirm completion |

| **Off-topic request** | Politely redirect to price tracking |

| **Ambiguous request** | Ask one clarifying question |

| **Error/failure** | Explain what went wrong, suggest alternatives |

| **Destructive action** | Confirm before deleting (from C1 guardrails) |

| **Unknown store** | Warn but proceed, explain auto-whitelist |

| **No results** | Acknowledge, suggest alternatives |

  

#### Scope Boundaries

  

**Will Do:**

- Track product prices from Canadian retailers

- Set price alerts and schedules

- Show price history and comparisons

- Search tracked products

- Explain how Perpee works

  

**Won't Do:**

- General knowledge questions (not a general assistant)

- Purchase products or process payments

- Access non-retail websites

- Provide financial/investment advice

- Track products outside Canada (MVP)

- Anything unrelated to price monitoring

  

#### System Prompt Template

  

```

You are Perpee, a friendly AI assistant specialized in monitoring product prices from Canadian online retailers.

  

## Your Capabilities

- Track product prices by URL

- Search products you're already tracking

- Set price alerts (target price, percent drop, any change, back in stock)

- Configure check schedules

- Show price history and comparisons across stores

- Web search for product URLs (shopping queries only)

  

## Your Personality

- Be friendly, helpful, and concise

- Use emojis sparingly: ğŸ“‰ price drops, ğŸ”” alerts, âœ… success, âš ï¸ issues

- Get to the point - users want quick answers

- Proactively suggest helpful follow-ups

  

## Important Rules

1. ONLY help with price tracking for Canadian retailers

2. If asked about something unrelated, politely redirect: "I'm focused on price tracking. Is there a product you'd like me to monitor?"

3. NEVER make up prices or data - only report what's in the database or freshly scraped

4. When a scrape fails, explain clearly and offer to retry or check later

5. Confirm before deleting products or alerts

6. For unknown stores, warn the user but proceed with the attempt

7. Keep responses brief unless the user asks for more detail

  

## Response Format

- Use short paragraphs, not long blocks

- For multiple products, use a brief list format

- Always include the current price when discussing a product

- Format prices as CAD (e.g., $149.99)

  

## Current Context

- User's tracked products and alerts are available via tools

- Price checks run daily at approximately 6 AM

- Chat history is session-only (not saved between visits)

```

  

#### Example Conversations

  

**Example 1: Adding a product**

```

User: Track this https://walmart.ca/product/nike-air-max

  

Perpee: âœ… Now tracking Nike Air Max 90 from Walmart!

  

Current price: $149.99

Last checked: Just now

  

Want me to set a price alert for this?

```

  

**Example 2: Off-topic request**

```

User: What's the weather like today?

  

Perpee: I'm focused on tracking product prices, so I can't help with weather. ğŸ™‚

  

Is there a product you'd like me to find or monitor?

```

  

**Example 3: Price drop notification context**

```

User: Show me the biggest drops

  

Perpee: ğŸ“‰ Here are your biggest price drops today:

  

1. **Sony WH-1000XM5** (Best Buy) - $279.99 â†’ $249.99 (-11%)

2. **Nike Air Max 90** (Walmart) - $159.99 â†’ $149.99 (-6%)

3. **Instant Pot Duo** (Amazon) - $129.99 â†’ $119.99 (-8%)

  

Want details on any of these?

```

  

**Example 4: Scrape failure**

```

User: Add https://unknownstore.ca/product/123

  

Perpee: âš ï¸ I wasn't able to extract product details from that page.

  

This could be because:

- The store layout isn't recognized yet

- The page requires login

- The product is no longer available

  

Want me to try again, or would you like to try a different URL?

```

  

**Example 5: Destructive action confirmation**

```

User: Delete all my Walmart products

  

Perpee: You have 12 products from Walmart. Are you sure you want to remove all of them?

  

This will also delete associated alerts and schedules.

  

Reply "yes" to confirm, or "no" to cancel.

```

  

**Example 6: Ambiguous request**

```

User: Set an alert

  

Perpee: Sure! Which product would you like to set an alert for?

  

You can say the product name, or paste a URL to add a new one.

```
#### Prompt Variables
| Variable | Source | Description |

|----------|--------|-------------|

| `{product_count}` | Database | Number of tracked products |

| `{store_count}` | Database | Number of active stores |

| `{recent_drops}` | Database | Count of price drops (24h) |

| `{user_name}` | Settings | Optional personalization (SaaS) |

  
---

## Component 2: Database Schema & Models

  

> âœ… **Status:** Complete

  

### 2.1 Data Retention Policy

  

| Table | Retention | Method |

|-------|-----------|--------|

| `products` | Forever | Soft delete |

| `alerts` | Forever | Soft delete |

| `schedules` | Forever | Soft delete |

| `canonical_products` | Forever | Soft delete |

| `price_history` | Forever | None |

| `scrape_logs` | 30 days | Daily cron hard delete |

| `notifications` | 90 days | Daily cron hard delete |

| `stores` | Forever | `is_active` flag |

  

### 2.2 Tables

  

#### `products`

  

| Column | Type | Notes |

|--------|------|-------|

| `id` | UUID | PK |

| `url` | TEXT | Full product URL |

| `store_domain` | TEXT | FK to stores |

| `name` | TEXT | Product title |

| `brand` | TEXT | Nullable |

| `upc` | TEXT | Nullable, for canonical matching |

| `current_price` | DECIMAL | Latest price |

| `original_price` | DECIMAL | Nullable (strikethrough price) |

| `currency` | TEXT | Default "CAD" |

| `in_stock` | BOOL | Nullable |

| `image_url` | TEXT | Nullable |

| `status` | TEXT | active, paused, error, archived |

| `canonical_id` | UUID | Nullable, FK to canonical_products |

| `last_checked_at` | DATETIME | |

| `last_successful_at` | DATETIME | |

| `consecutive_failures` | INT | Default 0 |

| `deleted_at` | DATETIME | Nullable, soft delete |

| `created_at` | DATETIME | |

| `updated_at` | DATETIME | |

  

#### `price_history`

  

| Column | Type | Notes |

|--------|------|-------|

| `id` | INT | PK, auto-increment |

| `product_id` | UUID | FK to products |

| `price` | DECIMAL | |

| `original_price` | DECIMAL | Nullable |

| `in_stock` | BOOL | Nullable |

| `scraped_at` | DATETIME | |

  

#### `alerts`

  

| Column | Type | Notes |

|--------|------|-------|

| `id` | UUID | PK |

| `product_id` | UUID | FK to products |

| `alert_type` | TEXT | target_price, percent_drop, any_change, back_in_stock |

| `target_value` | DECIMAL | Nullable (not needed for back_in_stock) |

| `is_active` | BOOL | Default true |

| `is_triggered` | BOOL | Default false |

| `triggered_at` | DATETIME | Nullable |

| `deleted_at` | DATETIME | Nullable, soft delete |

| `created_at` | DATETIME | |

  

#### `schedules`

  

| Column | Type | Notes |

|--------|------|-------|

| `id` | UUID | PK |

| `product_id` | UUID | Nullable, FK to products |

| `store_domain` | TEXT | Nullable (store-wide schedule) |

| `cron_expression` | TEXT | e.g., "0 6 * * *" |

| `is_active` | BOOL | Default true |

| `last_run_at` | DATETIME | Nullable |

| `next_run_at` | DATETIME | Nullable |

| `deleted_at` | DATETIME | Nullable, soft delete |

| `created_at` | DATETIME | |

  

#### `stores`

  

| Column | Type | Notes |

|--------|------|-------|

| `domain` | TEXT | PK, e.g., "walmart.ca" |

| `name` | TEXT | Display name |

| `is_whitelisted` | BOOL | P0/P1/P2 vs user-added |

| `is_active` | BOOL | Can disable problematic stores |

| `selectors` | JSON | CSS selectors for extraction |

| `rate_limit_rpm` | INT | Default 10 |

| `success_rate` | DECIMAL | Nullable, calculated |

| `last_success_at` | DATETIME | Nullable |

| `created_at` | DATETIME | |

| `updated_at` | DATETIME | |

  

#### `canonical_products`

  

| Column | Type | Notes |

|--------|------|-------|

| `id` | UUID | PK |

| `name` | TEXT | Normalized product name |

| `brand` | TEXT | Nullable |

| `upc` | TEXT | Nullable, for matching |

| `category` | TEXT | Nullable |

| `deleted_at` | DATETIME | Nullable, soft delete |

| `created_at` | DATETIME | |

  

#### `scrape_logs`

  

| Column | Type | Notes |

|--------|------|-------|

| `id` | INT | PK, auto-increment |

| `product_id` | UUID | FK to products |

| `success` | BOOL | |

| `strategy_used` | TEXT | json_ld, css, llm |

| `error_type` | TEXT | Nullable |

| `error_message` | TEXT | Nullable (sanitized, no secrets) |

| `response_time_ms` | INT | |

| `scraped_at` | DATETIME | |

  

#### `notifications`

  

| Column | Type | Notes |

|--------|------|-------|

| `id` | INT | PK, auto-increment |

| `alert_id` | UUID | Nullable, FK to alerts |

| `product_id` | UUID | FK to products |

| `channel` | TEXT | email, push |

| `status` | TEXT | pending, sent, failed |

| `payload` | JSON | What was sent |

| `sent_at` | DATETIME | Nullable |

| `error_message` | TEXT | Nullable |

| `created_at` | DATETIME | |

  

### 2.3 Indexes

  

| Table | Index Name | Columns | Purpose |

|-------|------------|---------|---------|

| `products` | idx_products_store | `store_domain` | Filter by store |

| `products` | idx_products_status | `status, deleted_at` | Active product queries |

| `products` | idx_products_canonical | `canonical_id` | Cross-store lookups |

| `products` | idx_products_upc | `upc` | Auto-matching |

| `price_history` | idx_price_product_date | `product_id, scraped_at DESC` | Time-series queries |

| `alerts` | idx_alerts_product | `product_id, is_active, deleted_at` | Check alerts on price change |

| `scrape_logs` | idx_scrape_product_date | `product_id, scraped_at DESC` | Recent failures |

| `notifications` | idx_notif_alert | `alert_id, created_at DESC` | Duplicate prevention |

  

### 2.4 Alert Logic

  

| Alert Type | Trigger Condition |

|------------|-------------------|

| `target_price` | Price â‰¤ target AND `in_stock` â‰  false |

| `percent_drop` | Price dropped X% AND `in_stock` â‰  false |

| `any_change` | Price changed AND `in_stock` â‰  false |

| `back_in_stock` | `in_stock` changed from false to true |

  

**Note:** `in_stock = NULL` (unknown) does not block alerts.

  

### 2.5 Canonical Product Matching

  

| Step | Action |

|------|--------|

| 1 | Extract UPC during scrape (if available) |

| 2 | Check for existing products with same UPC |

| 3 | If match found: auto-link + notify user |

| 4 | If no UPC: user can manually link via chat |

| 5 | On link: "Found same product at [store], linked for comparison!" |

  

### 2.6 Security Considerations

  

| Risk | Severity | Mitigation |

|------|----------|------------|

| URL injection | Medium | Validate URL format before storing |

| Scraped content XSS | High | Store only sanitized text, never raw HTML |

| JSON column injection | Low | SQLModel uses parameterized queries |

| Sensitive data in error_message | Low | Sanitize errors, never log tokens/keys |
### 2.7 Cross-Component Dependencies

  
| Component | Required Addition |

|-----------|-------------------|

| Component 3 (Scraper) | Extract `in_stock` and `upc` fields |

| Component 5 (Self-Healing) | Update `stores.selectors` in DB |

| Component 6 (Scheduler) | Daily pruning job for scrape_logs (30d) and notifications (90d) |

| Component 7 (Notifications) | Duplicate prevention via notifications table lookup |

| Component 1 (Agent) | Notify user on canonical product auto-linking |

  
---
## Component 3: Scraper Engine

### 3.1 Overview

The Scraper Engine handles all web scraping operations using Crawl4AI with Playwright. It implements a multi-strategy extraction approach prioritizing free methods before falling back to LLM-based extraction.

### Core Technologies

| Component | Technology |

|-----------|------------|

| Scraping Engine | Crawl4AI (Playwright underneath) |

| Extraction Strategies | JSON-LD, CSS, XPath, LLM (all native) |

| Rate Limiting | Crawl4AI `RateLimiter` |

| Concurrency | Crawl4AI `MemoryAdaptiveDispatcher` |

| Anti-Detection | Crawl4AI stealth mode + `UserAgentGenerator` |

| robots.txt | Crawl4AI native `check_robots_txt` |
## 3.2 Extraction Priority

Extraction attempts follow this waterfall to minimize LLM token costs:
| Priority | Strategy | Cost | Use Case |

|----------|----------|------|----------|

| 1st | JSON-LD | Free | Structured data in `<script type="application/ld+json">` |

| 2nd | CSS Selectors | Free | Known stores with pre-configured selectors |

| 3rd | XPath | Free | Edge cases CSS cannot handle (text content, sibling traversal) |

| 4th | LLM Extraction | Tokens | Unknown stores or when all else fails |

  

### Implementation

  

```python

from crawl4ai import JsonCssExtractionStrategy, JsonXPathExtractionStrategy, LLMExtractionStrategy

  

# Priority waterfall

strategies = [

Â  Â  ("json_ld", JsonCssExtractionStrategy(schema=json_ld_schema)),

Â  Â  ("css", JsonCssExtractionStrategy(schema=store_selectors)),

Â  Â  ("xpath", JsonXPathExtractionStrategy(schema=xpath_schema)),

Â  Â  ("llm", LLMExtractionStrategy(llm_config=llm_config, schema=product_schema))

]

```

  

## 3.3 Store Tiers

Simplified 2-tier system using existing database columns:

| Indicator | Tier | Behavior |
|-----------|------|----------|
| `is_whitelisted=TRUE` + `selectors` populated | **Known** | Use CSS/XPath extraction, fast & free |
| `is_whitelisted=FALSE` + `selectors` empty | **Scanned** | Must use `scan_website` tool first, then LLM extraction |

**Note:** Unknown URLs are no longer auto-allowed. Users must explicitly scan a new website before adding products from it. This prevents SSRF and ensures safe extraction.

## 3.4 Scan Website Tool

The `scan_website` tool analyzes a website's structure before adding it to the whitelist.

### Flow
```
User: "Can you scan bestdeals.ca so I can track products there?"
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Validate URL     â”‚ â†’ Block private IPs, check robots.txt
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Fetch Sample     â”‚ â†’ Load homepage + sample product page
    â”‚ Pages            â”‚    with stealth mode
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Structure        â”‚ â†’ Check for JSON-LD, product schema,
    â”‚ Analysis         â”‚    price elements, standard markup
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Security Check   â”‚ â†’ Validate no login required,
    â”‚                  â”‚    check for anti-bot measures
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Generate Report  â”‚ â†’ Return feasibility + suggested selectors
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ScanResult Response

```python
class ScanResult(BaseModel):
    domain: str
    feasible: bool                    # Can we extract products?
    confidence: float                 # 0.0-1.0 extraction confidence
    has_json_ld: bool                 # Structured data available?
    suggested_selectors: dict | None  # CSS selectors if found
    risks: list[str]                  # Potential issues
    recommendation: str               # Human-readable summary
```

### Example Output
```
âœ… Scan complete for bestdeals.ca

Feasibility: HIGH (confidence: 0.85)
- Found JSON-LD product schema
- Standard price markup detected
- No login required

Risks:
- Aggressive rate limiting detected (recommend 5s delays)

Would you like me to add this store to your whitelist?
```

### Security Checks
| Check | Action if Failed |
|-------|-----------------|
| Private IP | Block immediately |
| robots.txt disallows | Warn user, proceed only if they confirm |
| Login required | Mark as unfeasible |
| Heavy anti-bot | Warn user of potential issues |
| No product structure found | Mark as unfeasible |

## 3.5 Retry Strategy

Hybrid approach: Crawl4AI native + custom wrapper for UX feedback.
### Retry Matrix

| Error Type | Retry? | Attempts | Behavior |

|------------|--------|----------|----------|

| Network errors/timeouts | Yes | 3 | Exponential backoff |

| 5xx server errors | Yes | 3 | Exponential backoff |

| 429 rate limited | Yes | 3 | Exponential backoff |

| 403 forbidden | Yes | 1 | Single retry, then fail |

| 404 not found | No | 0 | Mark `broken_link` |

| CAPTCHA detected | No | 0 | Mark for review |

| Parse failure | No | 0 | Increment `consecutive_failures` (self-healing after 3) |

  
### User Feedback

Real-time messages during retries:

- "Retrying (1/3)..."

- "Retrying (2/3)..."

- On final failure: "Offer to notify when next scheduled check succeeds"

  
## 3.5 Block Detection & Evasion 

### Detection Layers

1. `result.success` (Crawl4AI native)

2. `result.status_code` (429/403/503)

3. Keyword scan in `result.html` (CAPTCHA, "access denied", "blocked")

4. Data validation (price/title present?)

### Progressive Evasion Strategy
| Level | Configuration | When Used |

|-------|---------------|-----------|

| 1 | Regular browser + stealth mode | Default |

| 2 | `UndetectedAdapter` + headless=False | After block detection |
### Implementation

  

```python

from crawl4ai import BrowserConfig, UndetectedAdapter

from crawl4ai.user_agent_generator import UserAgentGenerator

  

ua_generator = UserAgentGenerator()

  

# Level 1: Default

browser_config = BrowserConfig(

Â  Â  enable_stealth=True,

Â  Â  headless=True,

Â  Â  user_agent=ua_generator.generate(device_type="desktop", browser_type="chrome")

)

  

# Level 2: After block detected

adapter = UndetectedAdapter()

browser_config = BrowserConfig(

Â  Â  enable_stealth=True,

Â  Â  headless=False Â # Better evasion

)

```

## 3.6 Rate Limiting

Per-domain rate limiting using Crawl4AI native `RateLimiter`:

  

```python

from crawl4ai import RateLimiter

  

rate_limiter = RateLimiter(

Â  Â  base_delay=(2.0, 5.0), Â  Â  Â # Random 2-5s between requests

Â  Â  max_delay=60.0, Â  Â  Â  Â  Â  Â  # Cap at 60s after backoff

Â  Â  max_retries=3, Â  Â  Â  Â  Â  Â  Â # Aligns with retry strategy

Â  Â  rate_limit_codes=[429, 503, 403]

)

```

  
### Features

- **Per-domain tracking**: Automatic delay enforcement per domain

- **Exponential backoff**: On rate limit codes with jitter

- **Future enhancement**: Per-store overrides using `stores.rate_limit_rpm` column

  
## 3.7 Timeout Configuration

  
```python

from crawl4ai import CrawlerRunConfig

  

config = CrawlerRunConfig(

Â  Â  page_timeout=30000, Â  Â  Â  Â  Â  # 30s page load (matches C1 guardrail)

Â  Â  delay_before_return_html=1.0, # 1s extra wait for JS

Â  Â  wait_for="css:[data-automation='buybox-price']" Â # Per-store selector

)

```

  

| Setting | Value | Purpose |

|---------|-------|---------|

| `page_timeout` | 30000ms | Max page load time |

| `delay_before_return_html` | 1.0s | Wait for JS after load event |

| `wait_for` | Per-store | CSS selector to wait for (stored in `stores.selectors`) |

  

## 3.8 Concurrency Control

Memory-adaptive concurrency for Oracle Cloud free tier (1GB RAM):

  

```python

from crawl4ai import MemoryAdaptiveDispatcher

  

dispatcher = MemoryAdaptiveDispatcher(

Â  Â  memory_threshold_percent=70.0, Â # Auto-pause above 70%

Â  Â  check_interval=1.0, Â  Â  Â  Â  Â  Â  # Check every 1 second

Â  Â  max_session_permit=3 Â  Â  Â  Â  Â  Â # Max 3 concurrent browsers

)

```

### Resource Calculations

| Metric | Value |

|--------|-------|

| Browser memory | ~200MB each |

| Max instances | 3 |

| Total browser memory | ~600MB |

| Memory threshold | 70% of 1GB = 700MB |

| Batch performance | 50 products Ã· 3 concurrent Ã— 3.5s = ~60 seconds |
## 3.9 robots.txt Compliance

Always respect robots.txt:

```python

config = CrawlerRunConfig(

Â  Â  check_robots_txt=True

)

```

  

### Behavior
| Scenario | Action |

|----------|--------|

| URL allowed | Proceed with scrape |
| URL disallowed | Return 403, mark as `robots_blocked` |
| robots.txt unreachable | Proceed (assume allowed) |
| Cache | `/app/data/robots/` (mounted volume), 7-day TTL |

### User Notification

When blocked: "This product can't be monitored due to site restrictions."

## 3.10 Content Sanitization

Multi-layer defense against XSS and injection:

### Layer 1: Crawl4AI HTML Cleanup

  

```python

config = CrawlerRunConfig(

Â  Â  excluded_tags=["script", "style", "iframe", "form", "object", "embed"],

Â  Â  remove_forms=True

)

```

  

### Layer 2: Extraction Strategy

  

```python

schema = {

Â  Â  "fields": [

Â  Â  Â  Â  {"name": "title", "selector": "h1", "type": "text"}, Â # Returns text only

Â  Â  Â  Â  {"name": "price", "selector": ".price", "type": "text"}

Â  Â  ]

}

```

  

### Layer 3: Storage Sanitization (Python)

  

```python

import re

import html

  

def sanitize_scraped_content(value: str, max_length: int) -> str:

Â  Â  # Strip HTML tags

Â  Â  value = re.sub(r'<[^>]+>', '', value)

Â  Â  # Escape HTML entities

Â  Â  value = html.escape(value)

Â  Â  # Enforce length limit

Â  Â  return value[:max_length]

  

def validate_url(url: str) -> bool:

Â  Â  # Only allow http/https schemes

Â  Â  return url.startswith(('http://', 'https://'))

```

### Length Limits

| Field | Max Length |

|-------|------------|

| Product name | 500 chars |

| Description | 10,000 chars |

| URLs | 2,000 chars |

  

### Layer 4: Frontend (React)

  

- Default escaping (never use `dangerouslySetInnerHTML`)

- All scraped content displayed as text, not HTML
## 3.11 User-Agent Strategy

Crawl4AI native `UserAgentGenerator` with realistic browser signatures:

  

```python

from crawl4ai import BrowserConfig

from crawl4ai.user_agent_generator import UserAgentGenerator

  

ua_generator = UserAgentGenerator()

  

browser_config = BrowserConfig(

Â  Â  enable_stealth=True,

Â  Â  user_agent=ua_generator.generate(

Â  Â  Â  Â  device_type="desktop",

Â  Â  Â  Â  browser_type="chrome" Â # Rotate: chrome, firefox, edge

Â  Â  )

)

```

  

### Configuration

| Setting | Value |

|---------|-------|

| Device type | `desktop` (matches viewport) |

| Browser types | Rotate: `chrome`, `firefox`, `edge` |

| Rotation frequency | Per-request for batch scraping |

| Stealth mode | Always enabled |

  

### Ethical Consideration

  

Browser-like UAs are industry standard for price monitoring. We access public product pages, respect robots.txt, and rate-limit requests.

  

## 3.12 Security Risks & Mitigations

  

| Risk | Severity | Mitigation |

|------|----------|------------|

| SSRF (Server-Side Request Forgery) | HIGH | IP validation + redirect checks + 10MB limit + Content-Type validation |

| XSS from scraped content | HIGH | 4-layer sanitization (Crawl4AI + extraction + storage + frontend) |

| Bot detection/blocking | MEDIUM | Stealth mode + UserAgentGenerator + progressive evasion |

| Rate limiting/IP bans | MEDIUM | Native RateLimiter + exponential backoff + per-domain tracking |

| robots.txt violation | LOW | Always respect with `check_robots_txt=True` |

| Credential leakage in logs | MEDIUM | Never log full URLs with query params |

| Resource exhaustion | MEDIUM | MemoryAdaptiveDispatcher with 70% threshold |

| Malicious URL injection | MEDIUM | URL sanitization, private IP blocking |

  

## 3.13 Cross-Component Dependencies

  

| Component | Dependency |

|-----------|------------|

| Component 1 (Agent) | Calls `scrape_product` tool |

| Component 2 (Database) | Reads `stores.selectors`, writes `scrape_logs` |

| Component 5 (Self-Healing) | Updates `stores.selectors` when broken |

| Component 6 (Scheduler) | Triggers batch scrapes |

  

## 3.14 Module Structure

  

```

backend/src/scraper/

â”œâ”€â”€ __init__.py

â”œâ”€â”€ engine.py Â  Â  Â  Â  Â  # Main scraper orchestration

â”œâ”€â”€ strategies.py Â  Â  Â  # Extraction strategy implementations

â”œâ”€â”€ rate_limiter.py Â  Â  # Rate limiting configuration

â”œâ”€â”€ sanitization.py Â  Â  # Content sanitization utilities

â”œâ”€â”€ validators.py Â  Â  Â  # URL/IP validation (SSRF protection)

â””â”€â”€ user_agent.py Â  Â  Â  # User-agent generation wrapper

```

---

## Component 4: RAG System

### 4.1 Purpose

  

The RAG (Retrieval-Augmented Generation) system enables semantic search over tracked products. Users can find products using natural language queries like "that Nike shoe I added last week" or "electronics from Best Buy" instead of requiring exact keyword matches.

### 4.2 Core Responsibilities

| Responsibility | Description |

|----------------|-------------|

| **Product Indexing** | Embed and store product metadata when products are added |

| **Semantic Search** | Power the `search_products` agent tool with vector similarity |

| **Hybrid Search** | Combine vector search with metadata filters (store, price range) |

| **Index Maintenance** | Update embeddings on name/description change, remove on delete |

  

### 4.3 Technology Stack

  

| Component | Choice | Rationale |

|-----------|--------|-----------|

| **Vector DB** | ChromaDB | Proven, good Python API, migrates to pgvector for SaaS |

| **Embedding Model** | OpenAI `text-embedding-3-small` | $0.02/1M tokens (~$0.02/year), excellent quality |

| **Dimensions** | 1536 | Model default |

| **Distance Metric** | Cosine similarity | Standard for text embeddings |

  

### 4.4 What Gets Embedded

  

| Field | Embedded | Rationale |

|-------|----------|-----------|

| `name` | âœ… | Primary search target |

| `description` | âœ… | Rich semantic content |

| `store.name` | âœ… | "Find my Walmart products" |

| `category` | âœ… | "Show me electronics" |

| `brand` | âœ… | "Nike products" |

| `current_price` | âŒ | Use metadata filter instead |

| `url` | âŒ | Not semantically meaningful |

  

**Combined text for embedding:**

```

{brand} {name} - {category} from {store_name}

{description}

```

  

### 4.5 ChromaDB Collection Schema

  

```python

collection = chroma_client.get_or_create_collection(

Â  Â  name="products",

Â  Â  metadata={"hnsw:space": "cosine"}

)

  

# Document structure

{

Â  Â  "id": str(product.id), Â # UUID as string

Â  Â  "embedding": [...], Â  Â  Â # 1536 dimensions

Â  Â  "document": "Nike Air Max 90 - Footwear from Foot Locker\nClassic sneaker...",

Â  Â  "metadata": {

Â  Â  Â  Â  "store_domain": "footlocker.ca",

Â  Â  Â  Â  "store_name": "Foot Locker",

Â  Â  Â  Â  "brand": "Nike",

Â  Â  Â  Â  "category": "Footwear",

Â  Â  Â  Â  "current_price": 159.99,

Â  Â  Â  Â  "in_stock": True,

Â  Â  Â  Â  "created_at": "2024-12-17T10:00:00Z"

Â  Â  }

}

```

  

### 4.6 Search Strategy

  

```

User Query: "Nike shoes under $150"

Â  Â  Â  Â  Â  Â â”‚

Â  Â  Â  Â  Â  Â â–¼

Â  Â  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

Â  Â  â”‚ Embed Query Â â”‚ Â â†’ Vector for "Nike shoes"

Â  Â  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜

Â  Â  Â  Â  Â  Â â”‚

Â  Â  Â  Â  Â  Â â–¼

Â  Â  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

Â  Â  â”‚ ChromaDB Search Â â”‚ Â â†’ Top 10 by similarity

Â  Â  â”‚ with metadata Â  Â â”‚ Â  Â  where current_price < 150

Â  Â  â”‚ filters Â  Â  Â  Â  Â â”‚

Â  Â  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Â  Â  Â  Â  Â  Â â”‚

Â  Â  Â  Â  Â  Â â–¼

Â  Â  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

Â  Â  â”‚ SQLite Enrich Â  Â â”‚ Â â†’ Join with products table

Â  Â  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ Â  Â  for full product details

Â  Â  Â  Â  Â  Â â”‚

Â  Â  Â  Â  Â  Â â–¼

Â  Â  Return results to agent

```

  

### 4.7 Similarity Threshold

  

| Setting | MVP | Future (Large DB) |

|---------|-----|-------------------|

| **Threshold** | None (return top N) | 0.3 minimum |

| **Rationale** | Agent filters contextually | Reduce noise at scale |

  

**MVP behavior:** Return top 10 results regardless of score. Agent decides relevance based on context.

  

**Future:** When database grows beyond ~1000 products, add configurable threshold to filter low-relevance results before returning to agent.

  

### 4.8 Fallback Strategy

  

When ChromaDB is unavailable (corrupt file, failed to load):

  

| Step | Action |

|------|--------|

| 1 | Catch ChromaDB exception |

| 2 | Log warning with error details |

| 3 | Fall back to SQLite `LIKE` query |

| 4 | Include note in response: "basic search mode" |

  

```python

async def search(self, query: str, ...) -> list[SearchResult]:

Â  Â  try:

Â  Â  Â  Â  return await self._vector_search(query, ...)

Â  Â  except ChromaDBError as e:

Â  Â  Â  Â  logger.warning(f"ChromaDB unavailable, falling back to SQLite: {e}")

Â  Â  Â  Â  return await self._sqlite_fallback(query, ...)

```

  

### 4.9 Index Sync Strategy

  

| Event | Action |

|-------|--------|

| Product created | Embed and index immediately |

| Price/stock updated | Update metadata only (no re-embed) |

| Name/description changed | Re-embed and update |

| Product soft-deleted | Remove from ChromaDB |

| Product restored | Re-index |

  

```python

async def update_product(self, product: Product, old_product: Product):

Â  Â  if (product.name != old_product.name or

Â  Â  Â  Â  product.description != old_product.description):

Â  Â  Â  Â  # Re-embed - semantic content changed

Â  Â  Â  Â  await self.rag_service.index_product(product)

Â  Â  else:

Â  Â  Â  Â  # Metadata only - no re-embed needed

Â  Â  Â  Â  await self.rag_service.update_metadata(product)

```

  

### 4.10 API Design

  

```python

class RAGService:

Â  Â  async def index_product(self, product: Product) -> None:

Â  Â  Â  Â  """Add or update product in vector store (generates embedding)"""

Â  Â  async def update_metadata(self, product: Product) -> None:

Â  Â  Â  Â  """Update metadata without re-embedding (price, stock)"""

Â  Â  async def remove_product(self, product_id: UUID) -> None:

Â  Â  Â  Â  """Remove product from vector store"""

Â  Â  async def search(

Â  Â  Â  Â  self,

Â  Â  Â  Â  query: str,

Â  Â  Â  Â  store_domain: str | None = None,

Â  Â  Â  Â  min_price: float | None = None,

Â  Â  Â  Â  max_price: float | None = None,

Â  Â  Â  Â  in_stock: bool | None = None,

Â  Â  Â  Â  limit: int = 10

Â  Â  ) -> list[SearchResult]:

Â  Â  Â  Â  """Semantic search with optional metadata filters"""

Â  Â  async def reindex_all(self) -> int:

Â  Â  Â  Â  """Full reindex - admin recovery operation"""

```

  

### 4.11 Configuration

  

```python

class RAGSettings(BaseSettings):

Â  Â  # Embedding

Â  Â  embedding_model: str = "text-embedding-3-small"

Â  Â  embedding_dimensions: int = 1536

Â  Â  # ChromaDB

Â  Â  chromadb_path: str = "/app/data/chromadb"

Â  Â  collection_name: str = "products"

Â  Â  # Search

Â  Â  search_limit_default: int = 10

Â  Â  search_limit_max: int = 50

Â  Â  # similarity_threshold: float = 0.3 Â # Future: enable for large DB

```

  

### 4.12 Error Handling

  

| Scenario | Handling |

|----------|----------|

| Embedding API fails | Retry 3x with exponential backoff, then skip (log error) |

| Embedding API rate limit | Queue and retry after delay |

| ChromaDB unavailable | Fall back to SQLite LIKE search |

| Product not in index | Return from SQLite only, flag for reindex |

| Corrupt ChromaDB | Log error, trigger `reindex_all()` on next startup |

  

### 4.13 Security Considerations

  
| Risk | Severity | Mitigation |

|------|----------|------------|

| Prompt injection via product name | Low | Embeddings are mathematical vectors, not executable |

| Sensitive data in embeddings | Low | Only index public product info (name, description) |

| ChromaDB file access | Low | Same filesystem permissions as SQLite |

  
### 4.14 Cross-Component Dependencies

| Component | Dependency |

|-----------|------------|

| Component 1 (Agent) | Calls `search_products` tool â†’ RAGService.search() |

| Component 2 (Database) | RAG reads product data, syncs on CRUD operations |

| Component 5 (Self-Healing) | May trigger reindex if product data corrected |
### 4.15 Module Structure
```

backend/src/rag/

â”œâ”€â”€ __init__.py

â”œâ”€â”€ service.py Â  Â  Â  Â  Â # RAGService class

â”œâ”€â”€ embeddings.py Â  Â  Â  # OpenAI embedding wrapper

â”œâ”€â”€ search.py Â  Â  Â  Â  Â  # Search logic with hybrid filtering

â””â”€â”€ sync.py Â  Â  Â  Â  Â  Â  # Index maintenance (sync, reindex_all)

```

---

## Component 5: Self-Healing Module

### 5.1 Purpose

The Self-Healing Module automatically detects and recovers from scraping failures without user intervention. When website structures change and CSS selectors break, the module regenerates selectors using LLM extraction and updates the store configuration.

### 5.2 Core Responsibilities

| Responsibility | Description |

|----------------|-------------|

| **Failure Detection** | Identify broken selectors vs temporary errors |

| **Selector Regeneration** | Re-run LLM extraction to discover new selectors |

| **Store Health Tracking** | Monitor success rates, flag problematic stores |

| **Escalation** | Notify user when automatic recovery fails |

  

### 5.3 Failure Classification

  

| Failure Type | Cause | Self-Healable? |

|--------------|-------|----------------|

| **Parse failure** | Selectors return null/empty | âœ… Yes |

| **Price validation fail** | Price extracted but invalid ($0, negative, impossibly high) | âœ… Yes |

| **Structure change** | HTML changed, selectors don't match | âœ… Yes |

| **404 Not Found** | Product removed/URL changed | âŒ No (broken link) |

| **403/Blocked** | IP banned, anti-bot triggered | âŒ No (evasion issue) |

| **Network timeout** | Temporary server issue | âŒ No (retry handles this) |

  

### 5.4 Trigger Conditions

  

| Trigger | Threshold | Action |

|---------|-----------|--------|

| Single parse failure | 1 failure | Log, increment `consecutive_failures` |

| **Consecutive failures** | **3 failures** | **Trigger self-healing** |

| Store-wide failures | >50% products OR 5+ products failing | Flag store for review |

  

**Note:** This overrides the C3 retry matrix implication. Parse failures increment the counter; self-healing triggers only after 3 consecutive failures to avoid wasting LLM tokens on transient issues.

  

### 5.5 Recovery Flow

  

```

Scrape Attempt Failed (Parse Failure)

Â  Â  Â  Â  Â  Â  Â  â”‚

Â  Â  Â  Â  Â  Â  Â  â–¼

Â  Â â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

Â  Â â”‚ Increment Â  Â  Â  Â  Â  â”‚

Â  Â â”‚ consecutive_failuresâ”‚

Â  Â â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Â  Â  Â  Â  Â  Â  Â  â”‚

Â  Â  Â  Â  Â  Â  Â  â–¼

Â  Â  Â  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

Â  Â  Â  â”‚ Failures â‰¥ 3? â”‚â”€â”€â”€Noâ”€â”€â†’ Wait for next scheduled scrape

Â  Â  Â  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜

Â  Â  Â  Â  Â  Â  Â  â”‚ Yes

Â  Â  Â  Â  Â  Â  Â  â–¼

Â  Â  Â  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

Â  Â  Â  â”‚ Healing Â  Â  Â  â”‚

Â  Â  Â  â”‚ attempts < 3? â”‚â”€â”€â”€Noâ”€â”€â†’ Mark status=error, notify user

Â  Â  Â  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜

Â  Â  Â  Â  Â  Â  Â  â”‚ Yes

Â  Â  Â  Â  Â  Â  Â  â–¼

Â  Â â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

Â  Â â”‚ Trigger LLM Â  Â  Â  Â  â”‚

Â  Â â”‚ Selector Regen Â  Â  Â â”‚

Â  Â â”‚ (store-wide) Â  Â  Â  Â â”‚

Â  Â â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Â  Â  Â  Â  Â  Â  Â  â”‚

Â  Â  Â  Â  Â â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”

Â  Â  Â  Â  Â â”‚ Success? â”‚

Â  Â  Â  Â  Â â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜

Â  Â  Â  Â  Â  Â  Â  â”‚

Â  Â  Â  Â  Yes â”€â”€â”´â”€â”€ No

Â  Â  Â  Â  Â â”‚ Â  Â  Â  Â â”‚

Â  Â  Â  Â  Â â–¼ Â  Â  Â  Â â–¼

Â  Â â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” Â â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

Â  Â â”‚ Update Â  â”‚ Â â”‚ Increment Â  Â  Â  Â â”‚

Â  Â â”‚ store Â  Â â”‚ Â â”‚ healing_attempts â”‚

Â  Â â”‚ selectorsâ”‚ Â â”‚ Wait for next Â  Â â”‚

Â  Â â”‚ Reset Â  Â â”‚ Â â”‚ scheduled scrape â”‚

Â  Â â”‚ failures â”‚ Â â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Â  Â â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

  

### 5.6 Healing Scope

  

When self-healing triggers, it operates at **store level**:

  

| Scope | Behavior |

|-------|----------|

| **Selector regeneration** | Store-wide - updates `stores.selectors` |

| **Failure reset** | Product-specific - only triggering product resets |

| **Other products** | Reset on their next successful scrape |

  

**Rationale:** Selectors are stored per-store. If one product fails due to selector breakage, likely all products from that store are affected.

  

### 5.7 Selector Regeneration

  

```python

async def regenerate_selectors(self, product: Product, html: str) -> bool:

Â  Â  """

Â  Â  Regenerate store selectors using LLM extraction.

Â  Â  Called after 3 consecutive failures.

Â  Â  """

Â  Â  # 1. Run LLM extraction on current page HTML

Â  Â  result = await llm_extractor.extract(html, product_schema)

Â  Â  if not result.success:

Â  Â  Â  Â  return False

Â  Â  # 2. Ask LLM to generate CSS selectors for found elements

Â  Â  selectors = await llm_extractor.generate_selectors(

Â  Â  Â  Â  html=html,

Â  Â  Â  Â  extracted_data=result.data

Â  Â  )

Â  Â  # 3. Validate selectors work on current page

Â  Â  validated = await validate_selectors(html, selectors)

Â  Â  if validated:

Â  Â  Â  Â  # 4. Update store selectors in DB (affects all products)

Â  Â  Â  Â  await store_repo.update_selectors(

Â  Â  Â  Â  Â  Â  domain=product.store_domain,

Â  Â  Â  Â  Â  Â  selectors=selectors

Â  Â  Â  Â  )

Â  Â  Â  Â  # 5. Reset failures for this product only

Â  Â  Â  Â  await product_repo.reset_failures(product.id)

Â  Â  Â  Â  return True

Â  Â  return False

```

  

### 5.8 Healing Attempts Tracking

  

| Field | Location | Purpose |

|-------|----------|---------|

| `consecutive_failures` | `products` table | Tracks scrape failures (resets on success) |

| `healing_attempts` | In-memory or `products` table | Tracks healing tries (resets on healing success) |

  

**Flow across days:**

  

| Day | Event | `consecutive_failures` | `healing_attempts` | Action |

|-----|-------|------------------------|--------------------| -------|

| 1 | Scrape fails | 1 | 0 | Log |

| 1 | Scrape fails | 2 | 0 | Log |

| 1 | Scrape fails | 3 | 0 | Trigger healing â†’ fails |

| 1 | (after healing) | 3 | 1 | Wait |

| 2 | Scrape fails | 4 | 1 | Trigger healing â†’ fails |

| 2 | (after healing) | 4 | 2 | Wait |

| 3 | Scrape fails | 5 | 2 | Trigger healing â†’ fails |

| 3 | (after healing) | 5 | 3 | **Mark error, notify user** |

  

### 5.9 Store Health Tracking

  

| Metric | Calculation | Storage |

|--------|-------------|---------|

| **Success rate** | Successful / Total scrapes (7-day window) | `stores.success_rate` |

| **Last success** | Timestamp of last successful scrape | `stores.last_success_at` |

| **Failing products** | Count where `status=error` | Calculated on demand |

  

**Store flagging triggers:**

- **50% failure rate** across products from that store, OR

- **5+ products** in `error` status from that store  

### 5.10 LLM Budget

Self-healing uses the **shared daily token budget** (100k tokens/day from C1).

| Operation | Estimated Tokens |

|-----------|------------------|

| LLM extraction | 500-1000 |

| Selector generation | 300-500 |

| **Per healing attempt** | **~1000-1500** |
**Rationale:**

- Simplicity - one budget to track

- Self-limiting - mass breakage stops before budget exhaustion

- Healing typically runs overnight during scheduled scrapes, not competing with daytime chat

### 5.11 User Notifications

| Event | Notify? | Message |

|-------|---------|---------|

| Healing succeeds | âŒ No | Silent (logged only) |

| Healing fails (final) | âœ… Yes | Product-level notification |

| Store flagged | âœ… Yes | Store-level warning |

  

**Product failure notification:**

```

Unable to track "Nike Air Max 90" from Walmart.

The website may have changed.

[Retry] [Remove]

```

  

**Store flagged notification:**

```

âš ï¸ Multiple products from Walmart are failing.

The site may be blocking us or has changed significantly.

[View affected products]

```
### 5.12 Error Handling

| Scenario | Handling |

|----------|----------|

| LLM extraction fails | Count as failed healing attempt |

| LLM rate limited | Queue, retry with backoff |

| Selector validation fails | Count as failed healing attempt |

| Daily token budget exhausted | Skip healing, retry tomorrow |

| Store selectors update fails | Log error, don't reset product failures |

### 5.13 API Design
```python

class SelfHealingService:

Â  Â  async def handle_scrape_failure(

Â  Â  Â  Â  self,

Â  Â  Â  Â  product: Product,

Â  Â  Â  Â  error_type: str,

Â  Â  Â  Â  html: str | None

Â  Â  ) -> HealingResult:

Â  Â  Â  Â  """Called by scraper on failure. Decides whether to heal."""

Â  Â  async def attempt_healing(

Â  Â  Â  Â  self,

Â  Â  Â  Â  product: Product,

Â  Â  Â  Â  html: str

Â  Â  ) -> bool:

Â  Â  Â  Â  """Execute healing attempt. Returns success status."""

Â  Â  async def check_store_health(

Â  Â  Â  Â  self,

Â  Â  Â  Â  store_domain: str

Â  Â  ) -> StoreHealth:

Â  Â  Â  Â  """Calculate and return store health metrics."""

Â  Â  async def get_flagged_stores(self) -> list[StoreHealth]:

Â  Â  Â  Â  """List stores exceeding failure thresholds."""

Â  Â  async def get_failing_products(

Â  Â  Â  Â  self,

Â  Â  Â  Â  store_domain: str | None = None

Â  Â  ) -> list[Product]:

Â  Â  Â  Â  """List products with status=error."""

Â  Â  async def retry_product(self, product_id: UUID) -> bool:

Â  Â  Â  Â  """Manual retry triggered by user. Resets counters."""

```

  

### 5.14 Configuration

  

```python

class HealingSettings(BaseSettings):

Â  Â  # Thresholds

Â  Â  consecutive_failures_threshold: int = 3

Â  Â  max_healing_attempts: int = 3

Â  Â  store_failure_rate_threshold: float = 0.5 Â # 50%

Â  Â  store_failure_count_threshold: int = 5

Â  Â  # Health calculation

Â  Â  health_window_days: int = 7

```

  

### 5.15 Security Considerations
| Risk | Severity | Mitigation |

|------|----------|------------|

| LLM token exhaustion via forced failures | Medium | Shared budget cap, healing attempt limit |

| Malicious selector injection | Low | Validate selectors before saving |

| Infinite healing loops | Low | Max 3 attempts, then stop |

  

### 5.16 Cross-Component Dependencies

  

| Component | Dependency |

|-----------|------------|

| Component 3 (Scraper) | Calls `handle_scrape_failure()` on parse errors |

| Component 3 (Scraper) | Uses regenerated `stores.selectors` |

| Component 6 (Scheduler) | Healing runs during scheduled scrapes |

| Component 7 (Notifications) | Sends failure/flagging alerts |

| Component 4 (RAG) | May re-index if product data corrected |
### 5.17 Module Structure
```

backend/src/healing/

â”œâ”€â”€ __init__.py

â”œâ”€â”€ service.py Â  Â  Â  Â  Â # SelfHealingService class

â”œâ”€â”€ detector.py Â  Â  Â  Â  # Failure classification logic

â”œâ”€â”€ regenerator.py Â  Â  Â # Selector regeneration with LLM

â””â”€â”€ health.py Â  Â  Â  Â  Â  # Store health calculations

```

---

## Component 6: Scheduler

### 6.1 Purpose
The Scheduler manages automated price checking jobs using APScheduler. It handles product-level and store-level schedules, batches scrapes efficiently, and runs maintenance tasks like data retention cleanup.

### 6.2 Core Responsibilities

| Responsibility | Description |

|----------------|-------------|

| **Price Check Scheduling** | Run daily scrapes for tracked products |

| **Batch Optimization** | Group products by store for efficient scraping |

| **Maintenance Jobs** | Prune old scrape_logs (30d) and notifications (90d) |

| **Job Persistence** | Survive container restarts via SQLite jobstore |

| **Missed Job Recovery** | Coalesce missed runs into single execution |

  
### 6.3 Technology

| Component | Choice | Rationale |

|-----------|--------|-----------|

| **Scheduler** | APScheduler (AsyncIOScheduler) | Async-native, CRON support, mature |

| **Job Store** | SQLAlchemyJobStore (SQLite) | Persists jobs, survives restarts |

| **Triggers** | CronTrigger | Standard CRON expressions |

### 6.4 Job Types

| Job Type | Schedule | Purpose |
|----------|----------|---------|
| **Default daily scrape** | 6:00 AM Â± 30 min jitter | Check all active products |
| **Custom product schedule** | User-defined CRON | Per-product override |
| **Store-wide schedule** | User-defined CRON | All products from a store |
| **Data retention cleanup** | Weekly (Sunday 3 AM) | Prune scrape_logs (30d), notifications (90d) |
| **Store health calculation** | Daily (4 AM) | Calculate 7-day success rates |
### 6.5 Default Schedule

| Setting | Value | Rationale |

|---------|-------|-----------|

| **Time** | 6:00 AM EST | Fresh prices before user's day starts |
| **Jitter** | Â± 30 minutes | Anti-detection, spread load |
| **Timezone** | UTC internally, EST display | Consistent storage, user-friendly display |

  

```python

scheduler.add_job(

Â  Â  daily_scrape,

Â  Â  CronTrigger(hour=6, minute=0, jitter=1800), Â # 1800s = 30min

Â  Â  id='daily_scrape'

)

```
### 6.6 Schedule Hierarchy

When determining when to scrape a product:

| Priority | Level | Source |

|----------|-------|--------|

| 1 (Highest) | Product-specific | `schedules` where `product_id` is set |

| 2 | Store-wide | `schedules` where `store_domain` is set |

| 3 (Lowest) | System default | 6 AM daily with jitter |

  

### 6.7 Minimum Schedule Interval

| Setting | MVP | Future SaaS |

|---------|-----|-------------|

| **Minimum** | 24 hours (daily) | Hourly+ for paid tiers |

| **Validation** | Reject CRON running more than once per day | Tier-based limits |

  

```python

def validate_cron(cron_expression: str) -> bool:

Â  Â  if runs_more_than_once_per_day(cron_expression):

Â  Â  Â  Â  raise ValueError("Minimum schedule interval is 24 hours")

Â  Â  return True

```

### 6.8 Batch Strategy

Products are processed **store-by-store** for efficiency:

```

Daily Scrape Job Triggered

Â  Â  Â  Â  Â  â”‚

Â  Â  Â  Â  Â  â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚ Load active productsâ”‚

â”‚ GROUP BY store_domainâ”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Â  Â  Â  Â  Â  â”‚

Â  Â  Â  Â  Â  â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚ For each store: Â  Â  â”‚

â”‚ 1. Load selectors Â  â”‚

â”‚ 2. Init browser Â  Â  â”‚

â”‚ 3. Scrape products Â â”‚

â”‚ Â  Â (3 concurrent) Â  â”‚

â”‚ 4. Close browser Â  Â â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Â  Â  Â  Â  Â  â”‚

Â  Â  Â  Â  Â  â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚ For each result: Â  Â â”‚

â”‚ - Update prices Â  Â  â”‚

â”‚ - Check alerts Â  Â  Â â”‚

â”‚ - Handle failures Â  â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

  

**Rationale:**

- Reuse browser session per store

- Same selectors loaded once

- RateLimiter handles intra-store delays

- Natural gap between stores

### 6.9 APScheduler Configuration

  

```python

from apscheduler.schedulers.asyncio import AsyncIOScheduler

from apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore

from apscheduler.triggers.cron import CronTrigger

  

scheduler = AsyncIOScheduler(

Â  Â  jobstores={

Â  Â  Â  Â  'default': SQLAlchemyJobStore(url='sqlite:///data/perpee.db')

Â  Â  },

Â  Â  job_defaults={

Â  Â  Â  Â  'coalesce': True, Â  Â  Â  Â  Â  # Combine missed runs into one

Â  Â  Â  Â  'max_instances': 1, Â  Â  Â  Â  # Prevent overlapping runs

Â  Â  Â  Â  'misfire_grace_time': 3600 Â # 1 hour grace period

Â  Â  },

Â  Â  timezone='UTC'

)

```

### 6.10 Missed Job Handling

  

| Setting | Value | Behavior |

|---------|-------|----------|

| `coalesce` | `True` | Multiple missed runs â†’ single execution |

| `misfire_grace_time` | 3600 (1 hour) | Jobs missed by >1 hour are skipped |

| `max_instances` | 1 | Prevent overlapping job runs |

  

**Example scenario:**

- Container down from 5 AM to 10 AM

- 6 AM job was missed

- At 10 AM: Job runs once (catches up)
### 6.11 Schedule Limits

| Setting | MVP | Future SaaS |

|---------|-----|-------------|

| **Max schedules** | No limit | Tier-based (e.g., Free: 10, Pro: 100) |

### 6.12 Maintenance Jobs

#### Data Retention Cleanup (Weekly - Sunday 3 AM)
```python

async def cleanup_old_data():

Â  Â  # Prune scrape_logs older than 30 days

Â  Â  await db.execute(

Â  Â  Â  Â  delete(ScrapeLog).where(

Â  Â  Â  Â  Â  Â  ScrapeLog.scraped_at < datetime.now() - timedelta(days=30)

Â  Â  Â  Â  )

Â  Â  )

Â  Â  # Prune notifications older than 90 days

Â  Â  await db.execute(

Â  Â  Â  Â  delete(Notification).where(

Â  Â  Â  Â  Â  Â  Notification.created_at < datetime.now() - timedelta(days=90)

Â  Â  Â  Â  )

Â  Â  )

```

  

#### Store Health Calculation (Daily 4 AM)

  

```python

async def calculate_store_health():

Â  Â  for store in await get_all_stores():

Â  Â  Â  Â  # Calculate 7-day success rate

Â  Â  Â  Â  success_rate = await calculate_success_rate(

Â  Â  Â  Â  Â  Â  store.domain,

Â  Â  Â  Â  Â  Â  window_days=7

Â  Â  Â  Â  )

Â  Â  Â  Â  await update_store(store.domain, success_rate=success_rate)

```

  

### 6.13 API Design

  

```python

class SchedulerService:

Â  Â  async def start(self) -> None:

Â  Â  Â  Â  """Start scheduler on app startup"""

Â  Â  async def shutdown(self) -> None:

Â  Â  Â  Â  """Graceful shutdown, wait for running jobs"""

Â  Â  async def create_schedule(

Â  Â  Â  Â  self,

Â  Â  Â  Â  cron_expression: str,

Â  Â  Â  Â  product_id: UUID | None = None,

Â  Â  Â  Â  store_domain: str | None = None

Â  Â  ) -> Schedule:

Â  Â  Â  Â  """Create custom schedule (validates daily minimum)"""

Â  Â  async def update_schedule(

Â  Â  Â  Â  self,

Â  Â  Â  Â  schedule_id: UUID,

Â  Â  Â  Â  cron_expression: str | None = None,

Â  Â  Â  Â  is_active: bool | None = None

Â  Â  ) -> Schedule:

Â  Â  Â  Â  """Modify existing schedule"""

Â  Â  async def delete_schedule(self, schedule_id: UUID) -> bool:

Â  Â  Â  Â  """Remove schedule (soft delete)"""

Â  Â  async def run_now(self, product_id: UUID) -> ScrapeResult:

Â  Â  Â  Â  """Manual immediate scrape (bypasses schedule)"""

Â  Â  async def get_next_runs(self, limit: int = 10) -> list[ScheduledRun]:

Â  Â  Â  Â  """Preview upcoming scheduled runs"""

Â  Â  async def pause_schedule(self, schedule_id: UUID) -> Schedule:

Â  Â  Â  Â  """Temporarily disable a schedule"""

Â  Â  async def resume_schedule(self, schedule_id: UUID) -> Schedule:

Â  Â  Â  Â  """Re-enable a paused schedule"""

```

  

### 6.14 Lifecycle Integration

  

```python

# In main.py

from contextlib import asynccontextmanager

  

@asynccontextmanager

async def lifespan(app: FastAPI):

Â  Â  # Startup

Â  Â  scheduler_service.start()

Â  Â  yield

Â  Â  # Shutdown

Â  Â  await scheduler_service.shutdown()

  

app = FastAPI(lifespan=lifespan)

```

  

### 6.15 Configuration

  

```python

class SchedulerSettings(BaseSettings):

Â  Â  # Default schedule

Â  Â  default_scrape_hour: int = 6

Â  Â  default_scrape_minute: int = 0

Â  Â  default_jitter_seconds: int = 1800 Â # 30 min

Â  Â  # Job behavior

Â  Â  misfire_grace_time: int = 3600 Â # 1 hour

Â  Â  max_instances: int = 1

Â  Â  coalesce: bool = True

Â  Â  # Maintenance

Â  Â  cleanup_hour: int = 3

Â  Â  health_calc_hour: int = 4

Â  Â  # Limits

Â  Â  min_schedule_interval_hours: int = 24

Â  Â  # Timezone

Â  Â  timezone: str = "UTC"

```

  

### 6.16 Error Handling

  

| Scenario | Handling |

|----------|----------|

| Job raises exception | Log error, job runs again next scheduled time |

| Database unavailable | Retry with backoff, alert if persistent |

| Scheduler fails to start | App startup fails (critical dependency) |

| Job runs too long | No timeout (batching handles via scraper timeouts) |

  

### 6.17 Security Considerations

  

| Risk | Severity | Mitigation |

|------|----------|------------|

| CRON injection | Low | Validate CRON syntax before storing |

| Job flooding | Low | `max_instances=1`, daily minimum interval |

| Resource exhaustion | Medium | MemoryAdaptiveDispatcher limits (from C3) |

  

### 6.18 Cross-Component Dependencies  

| Component | Dependency |

|-----------|------------|

| Component 1 (Agent) | `create_schedule` tool calls SchedulerService |

| Component 2 (Database) | Reads `schedules` table, jobstore uses SQLite |

| Component 3 (Scraper) | Scheduler triggers batch scrapes |

| Component 5 (Self-Healing) | Healing attempts run during scheduled scrapes |

| Component 7 (Notifications) | Scheduler triggers alert checks after scrapes |

  

### 6.19 Module Structure
```

backend/src/scheduler/

â”œâ”€â”€ __init__.py

â”œâ”€â”€ service.py Â  Â  Â  Â  Â # SchedulerService class

â”œâ”€â”€ jobs.py Â  Â  Â  Â  Â  Â  # Job definitions (daily_scrape, cleanup, health)

â”œâ”€â”€ batching.py Â  Â  Â  Â  # Store-grouped batch logic

â””â”€â”€ triggers.py Â  Â  Â  Â  # CRON parsing and validation

```

---

## Component 7: Notifications

### 7.1 Purpose

The Notifications module sends alerts to users when price conditions are met or system events occur. MVP supports email only via Resend.

### 7.2 Core Responsibilities

| Responsibility | Description |
|----------------|-------------|
| **Alert Delivery** | Send email notifications when alerts trigger |
| **Duplicate Prevention** | Avoid re-notifying until price changes again |
| **Retry Handling** | Retry failed sends with backoff |
| **System Notifications** | Scraper failures, store issues |

### 7.3 Channel

| Channel | Provider | Status |
|---------|----------|--------|
| **Email** | Resend | âœ… MVP |
| Slack/Discord | - | ğŸ”® Post-MVP |

### 7.4 Notification Types

| Type | Trigger | Channel | Source |
|------|---------|---------|--------|
| **Price Alert** | Alert condition met (target_price, percent_drop, any_change) | Email | Scheduler |
| **Back in Stock** | Product `in_stock` changed from false to true | Email | Scheduler |
| **Product Error** | Self-healing failed after 3 attempts | Email | Self-Healing (C5) |
| **Store Flagged** | Store health threshold exceeded (50% OR 5+) | Email | Self-Healing (C5) |

  

### 7.5 Duplicate Prevention

Notifications are suppressed until the price changes again:

```python

async def should_notify(alert: Alert, product: Product) -> bool:

Â  Â  last_notification = await get_last_notification(

Â  Â  Â  Â  alert_id=alert.id,

Â  Â  Â  Â  product_id=product.id

Â  Â  )

Â  Â  if not last_notification:

Â  Â  Â  Â  return True Â # Never notified before

Â  Â  last_notified_price = last_notification.payload.get("price")

Â  Â  return product.current_price != last_notified_price

```
  

### 7.6 Notification Timing

| Setting | MVP |

|---------|-----|

| **Timing** | Immediate |

| **Digest option** | Not implemented |

**MVP behavior:** Send notification immediately when alert triggers during scheduled scrape.

  
### 7.7 User Preferences

Stored in environment variables (MVP single user):

```env

# .env

USER_EMAIL=user@example.com
EMAIL_ENABLED=true
```

  
```python

class NotificationSettings(BaseSettings):

Â  Â  user_email: str
Â  Â  email_enabled: bool = True

```  

### 7.8 Email Implementation (Resend)
```python

import resend

  

async def send_email(to: str, subject: str, html: str) -> bool:

Â  Â  resend.api_key = settings.resend_api_key

Â  Â  response = await resend.Emails.send({

Â  Â  Â  Â  "from": "Perpee <alerts@perpee.app>",

Â  Â  Â  Â  "to": to,

Â  Â  Â  Â  "subject": subject,

Â  Â  Â  Â  "html": html

Â  Â  })

Â  Â  return response.get("id") is not None

```

  
### 7.9 Retry Strategy

Immediate retry with exponential backoff:

```python

async def send_with_retry(

Â  Â  send_func: Callable,

Â  Â  max_retries: int = 3

) -> str:

Â  Â  for attempt in range(max_retries):

Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  success = await send_func()

Â  Â  Â  Â  Â  Â  if success:

Â  Â  Â  Â  Â  Â  Â  Â  return "sent"

Â  Â  Â  Â  except TransientError:

Â  Â  Â  Â  Â  Â  pass

Â  Â  Â  Â  if attempt < max_retries - 1:

Â  Â  Â  Â  Â  Â  await asyncio.sleep(2 ** attempt) Â # 1s, 2s, 4s

Â  Â  return "failed"

```

  

| Attempt | Delay | Total Elapsed |

|---------|-------|---------------|

| 1 | 0s | 0s |

| 2 | 1s | 1s |

| 3 | 2s | 3s |

| Fail | - | ~3-5s |

  

### 7.10 Message Templates

#### Price Alert Email
```

Subject: ğŸ”” Price Drop: {product_name}

  

{product_name} dropped to {new_price}!

  

Was: {old_price}

Now: {new_price}

Savings: {savings_amount} ({savings_percent}%)

  

{product_url}

  

Store: {store_name}

```

  

#### Product Error Email

```

Subject: âš ï¸ Unable to track: {product_name}

  

We're having trouble tracking {product_name} from {store_name}.

  

The website may have changed or is blocking our access.

We'll keep trying, but you may want to check the product manually.

  

[View Product] [Remove from Tracking]

```

  

#### Store Flagged Email

  

```

Subject: âš ï¸ Multiple products failing from {store_name}

  

{failing_count} products from {store_name} are having issues.

  

The site may be blocking us or has changed significantly.

  

[View Affected Products]

```

  

### 7.11 API Design

  

```python

class NotificationService:

Â  Â  async def send_alert(

Â  Â  Â  Â  self,

Â  Â  Â  Â  alert: Alert,

Â  Â  Â  Â  product: Product,

Â  Â  Â  Â  old_price: float,

Â  Â  Â  Â  new_price: float

Â  Â  ) -> Notification:

Â  Â  Â  Â  """Send notification for triggered alert"""

Â  Â  async def send_product_error(

Â  Â  Â  Â  self,

Â  Â  Â  Â  product: Product

Â  Â  ) -> Notification:

Â  Â  Â  Â  """Notify about product tracking failure"""

Â  Â  async def send_store_flagged(

Â  Â  Â  Â  self,

Â  Â  Â  Â  store: Store,

Â  Â  Â  Â  failing_count: int

Â  Â  ) -> Notification:

Â  Â  Â  Â  """Notify about store-wide issues"""

Â  Â  async def get_history(

Â  Â  Â  Â  self,

Â  Â  Â  Â  limit: int = 50,

Â  Â  Â  Â  channel: str | None = None

Â  Â  ) -> list[Notification]:

Â  Â  Â  Â  """Get recent notification history"""

```

  

### 7.12 Configuration

  

```python

class NotificationSettings(BaseSettings):

Â  Â  # Email (Resend)

Â  Â  resend_api_key: str

Â  Â  user_email: str

Â  Â  email_enabled: bool = True

Â  Â  email_from: str = "Perpee <alerts@perpee.app>"

Â  Â  # Retry

Â  Â  max_retry_attempts: int = 3

Â  Â  # Templates

Â  Â  templates_dir: str = "src/notifications/templates"

```

  

### 7.13 Error Handling

  

| Scenario | Handling |

|----------|----------|

| Resend API error | Retry 3x, then mark failed |


| Invalid email address | Mark failed, log error |

| Rate limited by provider | Retry with backoff |

| Template rendering error | Log error, send plain text fallback |

  

### 7.14 Security Considerations

  

| Risk | Severity | Mitigation |

|------|----------|------------|

| Email address exposure | Low | Stored in env, not DB |

| Notification content injection | Low | Escape all dynamic content in templates |

| API key exposure | Medium | Never log API keys, use env vars |

  

### 7.15 Cross-Component Dependencies

  

| Component | Dependency |

|-----------|------------|

| Component 2 (Database) | Writes to `notifications` table |

| Component 5 (Self-Healing) | Calls `send_product_error()`, `send_store_flagged()` |

| Component 6 (Scheduler) | Triggers alert checks after scrapes, prunes old notifications |

| Component 8 (API) | Exposes notification history endpoint |

  

### 7.16 Module Structure

  

```

backend/src/notifications/

â”œâ”€â”€ __init__.py

â”œâ”€â”€ service.py Â  Â  Â  Â  Â # NotificationService class

â”œâ”€â”€ channels/

â”‚ Â  â”œâ”€â”€ __init__.py

â”‚ Â  â”œâ”€â”€ email.py Â  Â  Â  Â # Resend integration


â”œâ”€â”€ templates/

â”‚ Â  â”œâ”€â”€ price_alert.html

â”‚ Â  â”œâ”€â”€ product_error.html

â”‚ Â  â””â”€â”€ store_flagged.html

â””â”€â”€ formatters.py Â  Â  Â  # Message formatting utilities

```

---

## Component 8: API Endpoints

### 8.1 Purpose

The API layer exposes FastAPI endpoints for the frontend and handles real-time chat via WebSocket. It serves as the interface between the React UI and all backend services.

### 8.2 Core Responsibilities

| Responsibility | Description |

|----------------|-------------|

| **REST Endpoints** | CRUD operations for products, alerts, schedules |

| **WebSocket Chat** | Real-time agent conversation with streaming |

| **Static Files** | Serve React frontend build |

| **Error Handling** | Standardized error responses |

| **OpenAPI Docs** | Auto-generated API documentation |

  

### 8.3 Key Decisions

  

| Decision | Choice | Rationale |

|----------|--------|-----------|

| **Chat interface** | WebSocket only | Streaming responses, tool call visibility |

| **API versioning** | None for MVP | Single user, add `/v1/` for SaaS |

| **Pagination** | Offset-based | Simple, familiar, good enough for 500 products |

| **Rate limiting** | None for MVP | Agent guardrails handle expensive ops |

| **CORS** | Localhost whitelist | Dev only, same-origin in production |

| **Authentication** | None for MVP | Add Supabase Auth for SaaS |

  

### 8.4 Endpoint Groups

  

| Group | Base Path | Purpose |

|-------|-----------|---------|

| **Chat** | `/api/chat` | WebSocket for agent conversation |

| **Products** | `/api/products` | Product CRUD + price history |

| **Alerts** | `/api/alerts` | Alert CRUD |

| **Schedules** | `/api/schedules` | Schedule CRUD |

| **Stores** | `/api/stores` | Store list + health status |

| **System** | `/api/health`, `/api/stats` | Health check, dashboard stats |

| **Static** | `/` | React frontend |

  

### 8.5 REST Endpoints

  

#### Products

  

| Method | Path | Purpose | Response |

|--------|------|---------|----------|

| `GET` | `/api/products` | List tracked products | Paginated list |

| `GET` | `/api/products/{id}` | Get product details | Product |

| `POST` | `/api/products` | Add product (via URL) | Product |

| `DELETE` | `/api/products/{id}` | Remove product (soft delete) | Success |

| `GET` | `/api/products/{id}/history` | Price history | List of price points |

| `POST` | `/api/products/{id}/refresh` | Manual scrape now | Scrape result |

  

#### Alerts

  

| Method | Path | Purpose | Response |

|--------|------|---------|----------|

| `GET` | `/api/alerts` | List alerts | Paginated list |

| `GET` | `/api/alerts/{id}` | Get alert details | Alert |

| `POST` | `/api/alerts` | Create alert | Alert |

| `PATCH` | `/api/alerts/{id}` | Update alert | Alert |

| `DELETE` | `/api/alerts/{id}` | Remove alert (soft delete) | Success |

  

#### Schedules

  

| Method | Path | Purpose | Response |

|--------|------|---------|----------|

| `GET` | `/api/schedules` | List schedules | Paginated list |

| `POST` | `/api/schedules` | Create schedule | Schedule |

| `PATCH` | `/api/schedules/{id}` | Update schedule | Schedule |

| `DELETE` | `/api/schedules/{id}` | Remove schedule (soft delete) | Success |

  

#### Stores

  

| Method | Path | Purpose | Response |

|--------|------|---------|----------|

| `GET` | `/api/stores` | List supported stores | List of stores |

| `GET` | `/api/stores/{domain}/health` | Store health metrics | StoreHealth |

  

#### System

  

| Method | Path | Purpose | Response |

|--------|------|---------|----------|

| `GET` | `/api/health` | Health check | `{"status": "ok"}` |

| `GET` | `/api/stats` | Dashboard stats | Stats object |

  

### 8.6 WebSocket Chat

  

#### Connection

  

```

ws://localhost:8000/api/chat/ws

```

  

#### Message Flow

  

```

Client Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Server

Â  â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â â”‚

Â  â”‚â”€â”€â”€â”€ Connect â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚

Â  â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â â”‚

Â  â”‚â—„â”€â”€â”€â”€ {"type": "welcome", ...} â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚

Â  â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â â”‚

Â  â”‚â”€â”€â”€â”€ {"message": "Track Nike..."} â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚

Â  â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â â”‚

Â  â”‚â—„â”€â”€â”€â”€ {"type": "thinking"} â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚

Â  â”‚â—„â”€â”€â”€â”€ {"type": "tool_call", ...} â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚

Â  â”‚â—„â”€â”€â”€â”€ {"type": "tool_result", ...} â”€â”€â”€â”€â”€â”€â”€â”‚

Â  â”‚â—„â”€â”€â”€â”€ {"type": "response", ...} â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚

Â  â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â â”‚

```

  

#### Message Types

  

| Type | Direction | Purpose |

|------|-----------|---------|

| `welcome` | Server â†’ Client | Initial greeting with capabilities |

| `message` | Client â†’ Server | User message |

| `thinking` | Server â†’ Client | Agent is processing |

| `tool_call` | Server â†’ Client | Agent calling a tool |

| `tool_result` | Server â†’ Client | Tool execution result |

| `response` | Server â†’ Client | Agent text response |

| `error` | Server â†’ Client | Error occurred |

  

#### Implementation

  

```python

@app.websocket("/api/chat/ws")

async def chat_websocket(websocket: WebSocket):

Â  Â  await websocket.accept()

Â  Â  # Send welcome message

Â  Â  await websocket.send_json({

Â  Â  Â  Â  "type": "welcome",

Â  Â  Â  Â  "content": WELCOME_MESSAGE

Â  Â  })

Â  Â  try:

Â  Â  Â  Â  while True:

Â  Â  Â  Â  Â  Â  data = await websocket.receive_json()

Â  Â  Â  Â  Â  Â  message = data.get("message", "")

Â  Â  Â  Â  Â  Â  async for chunk in agent.run_stream(message):

Â  Â  Â  Â  Â  Â  Â  Â  await websocket.send_json({

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "type": chunk.type,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "content": chunk.content

Â  Â  Â  Â  Â  Â  Â  Â  })

Â  Â  except WebSocketDisconnect:

Â  Â  Â  Â  pass Â # Client disconnected

```

  

### 8.7 Pagination

  

Offset-based pagination for list endpoints:

  

#### Request

  

```

GET /api/products?page=2&limit=20&store=walmart.ca&status=active

```

  

#### Response

  

```json

{

Â  "data": [

Â  Â  {"id": "...", "name": "...", ...},

Â  Â  ...

Â  ],

Â  "meta": {

Â  Â  "page": 2,

Â  Â  "limit": 20,

Â  Â  "total": 150,

Â  Â  "total_pages": 8

Â  }

}

```

  

#### Implementation

  

```python

@router.get("/api/products")

async def list_products(

Â  Â  page: int = Query(1, ge=1),

Â  Â  limit: int = Query(20, ge=1, le=100),

Â  Â  store: str | None = None,

Â  Â  status: str | None = None

) -> PaginatedResponse[ProductOut]:

Â  Â  offset = (page - 1) * limit

Â  Â  products, total = await product_repo.list(

Â  Â  Â  Â  offset=offset,

Â  Â  Â  Â  limit=limit,

Â  Â  Â  Â  store=store,

Â  Â  Â  Â  status=status

Â  Â  )

Â  Â  return {

Â  Â  Â  Â  "data": products,

Â  Â  Â  Â  "meta": {

Â  Â  Â  Â  Â  Â  "page": page,

Â  Â  Â  Â  Â  Â  "limit": limit,

Â  Â  Â  Â  Â  Â  "total": total,

Â  Â  Â  Â  Â  Â  "total_pages": ceil(total / limit)

Â  Â  Â  Â  }

Â  Â  }

```

### 8.8 Response Formats
#### Success Response

  

```json

{

Â  "data": { ... }

}

```

#### Success Response (List)

  

```json

{

Â  "data": [ ... ],

Â  "meta": {

Â  Â  "page": 1,

Â  Â  "limit": 20,

Â  Â  "total": 100

Â  }

}

```
#### Error Response

```json

{

Â  "error": {

Â  Â  "code": "PRODUCT_NOT_FOUND",

Â  Â  "message": "Product with ID xyz not found",

Â  Â  "details": null

Â  }

}

```

### 8.9 Error Codes

| Code | HTTP Status | Description |

|------|-------------|-------------|

| `VALIDATION_ERROR` | 422 | Request validation failed |

| `PRODUCT_NOT_FOUND` | 404 | Product ID doesn't exist |

| `ALERT_NOT_FOUND` | 404 | Alert ID doesn't exist |

| `SCHEDULE_NOT_FOUND` | 404 | Schedule ID doesn't exist |

| `STORE_NOT_FOUND` | 404 | Store domain doesn't exist |

| `SCRAPE_FAILED` | 500 | Failed to scrape product |

| `INVALID_URL` | 400 | URL format invalid |

| `RATE_LIMITED` | 429 | Too many requests (agent guardrail) |

| `INTERNAL_ERROR` | 500 | Unexpected server error |
### 8.10 CORS Configuration
```python

from fastapi.middleware.cors import CORSMiddleware

  

# Only needed for development (Vite dev server)

# Production serves frontend from same origin

app.add_middleware(

Â  Â  CORSMiddleware,

Â  Â  allow_origins=[

Â  Â  Â  Â  "http://localhost:5173", Â # Vite dev server

Â  Â  Â  Â  "http://localhost:3000", Â # Alternative dev port

Â  Â  ],

Â  Â  allow_credentials=True,

Â  Â  allow_methods=["*"],

Â  Â  allow_headers=["*"],

)

```
### 8.11 Static File Serving

```python

from fastapi.staticfiles import StaticFiles

  

# Serve React build in production

app.mount("/", StaticFiles(directory="static", html=True), name="static")

```

  

**Build process:**

1. `cd frontend && npm run build`

2. Copy `frontend/dist/*` to `backend/static/`

3. FastAPI serves static files at `/`
### 8.12 App Lifecycle
```python

from contextlib import asynccontextmanager

  

@asynccontextmanager

async def lifespan(app: FastAPI):

Â  Â  # Startup

Â  Â  await database.connect()

Â  Â  scheduler_service.start()

Â  Â  yield

Â  Â  # Shutdown

Â  Â  await scheduler_service.shutdown()

Â  Â  await database.disconnect()

  

app = FastAPI(

Â  Â  title="Perpee API",

Â  Â  description="AI-powered price monitoring agent",

Â  Â  version="0.1.0",

Â  Â  lifespan=lifespan,

Â  Â  docs_url="/api/docs",

Â  Â  redoc_url="/api/redoc",

Â  Â  openapi_url="/api/openapi.json"

)

```
### 8.13 Configuration

```python

class APISettings(BaseSettings):

Â  Â  # Server

Â  Â  host: str = "0.0.0.0"

Â  Â  port: int = 8000

Â  Â  debug: bool = False

Â  Â  # Pagination

Â  Â  default_page_size: int = 20

Â  Â  max_page_size: int = 100

Â  Â  # CORS (dev only)

Â  Â  cors_origins: list[str] = [

Â  Â  Â  Â  "http://localhost:5173",

Â  Â  Â  Â  "http://localhost:3000",

Â  Â  ]

Â  Â  # Docs

Â  Â  docs_enabled: bool = True

```

  

### 8.14 Security Considerations

| Risk | Severity | Mitigation |

|------|----------|------------|

| API error leakage | Medium | `debug=False`, generic error messages in production |

| WebSocket abuse | Low | Connection limit, message size limit |

| Mass data exposure | Low | Pagination limits, no bulk export |

| CORS misconfiguration | Medium | Whitelist only localhost for dev |

### 8.15 Cross-Component Dependencies

  
| Component | Dependency |

|-----------|------------|

| Component 1 (Agent) | WebSocket chat invokes agent |

| Component 2 (Database) | All CRUD operations |

| Component 4 (RAG) | Product search via agent |

| Component 5 (Self-Healing) | Store health endpoint |

| Component 6 (Scheduler) | Lifecycle start/stop, manual refresh |

| Component 7 (Notifications) | Notification history endpoint |

  
### 8.16 Module Structure

```

backend/src/api/

â”œâ”€â”€ __init__.py

â”œâ”€â”€ main.py Â  Â  Â  Â  Â  Â  # FastAPI app, lifespan, middleware

â”œâ”€â”€ routes/

â”‚ Â  â”œâ”€â”€ __init__.py

â”‚ Â  â”œâ”€â”€ products.py Â  Â  # Product endpoints

â”‚ Â  â”œâ”€â”€ alerts.py Â  Â  Â  # Alert endpoints

â”‚ Â  â”œâ”€â”€ schedules.py Â  Â # Schedule endpoints

â”‚ Â  â”œâ”€â”€ stores.py Â  Â  Â  # Store endpoints

â”‚ Â  â”œâ”€â”€ chat.py Â  Â  Â  Â  # WebSocket handler

â”‚ Â  â””â”€â”€ health.py Â  Â  Â  # Health + stats endpoints

â”œâ”€â”€ schemas/

â”‚ Â  â”œâ”€â”€ __init__.py

â”‚ Â  â”œâ”€â”€ products.py Â  Â  # Product request/response models

â”‚ Â  â”œâ”€â”€ alerts.py Â  Â  Â  # Alert models

â”‚ Â  â”œâ”€â”€ schedules.py Â  Â # Schedule models

â”‚ Â  â”œâ”€â”€ stores.py Â  Â  Â  # Store models

â”‚ Â  â””â”€â”€ common.py Â  Â  Â  # Pagination, errors

â”œâ”€â”€ dependencies.py Â  Â  # Dependency injection

â””â”€â”€ exceptions.py Â  Â  Â  # Custom exception handlers

```

---
## Component 9: Web UI (Frontend)

### 9.1 Purpose

The Web UI provides a React-based single-page application for interacting with Perpee. It features a 3-column layout with persistent chat access, allowing users to manage products, alerts, and schedules while conversing with the AI agent.
### 9.2 Core Responsibilities

| Responsibility | Description |

|----------------|-------------|

| **Product Management** | View, add, remove tracked products |

| **Alert Configuration** | Create and manage price alerts |

| **Schedule Management** | Configure custom check schedules |

| **Chat Interface** | Real-time conversation with AI agent |

| **Price Visualization** | Charts showing price history |

| **Store Health** | View store status and health metrics |

  

### 9.3 Technology Stack
| Component | Technology | Rationale |

|-----------|------------|-----------|

| **Framework** | Vite + React | Fast dev, simple deployment |

| **App Type** | Single Page Application (SPA) | Served by FastAPI |

| **UI Library** | shadcn/ui + Tailwind CSS | Customizable, accessible |

| **State (Server)** | React Query (TanStack) | Caching, background refresh |

| **State (Client)** | useState/useContext | Zustand deferred for MVP |

| **Forms** | React Hook Form + Zod | Validation, type-safe |

| **Routing** | React Router v6 | Standard SPA routing |

| **Charts** | Recharts | Price history visualization |

| **Toasts** | Sonner | Notifications, alerts |

| **Dates** | date-fns | Formatting, manipulation |

| **Icons** | Lucide React | Consistent icon set |

| **Sanitization** | DOMPurify | XSS prevention |

  

### 9.4 Layout Structure

  

```

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Header (optional) Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  â”‚

â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤

â”‚ Â  Â  Â  Â  Â  Â â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  â”‚

â”‚ Â Sidebar Â  â”‚ Â  Â  Â  Â  Main Content Â  Â  Â  Â  Â  Â â”‚ Â  Â Chat Panel Â  Â  â”‚

â”‚ Â  (Nav) Â  Â â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  â”‚ Â  (Collapsible) Â  â”‚

â”‚ Â  Â  Â  Â  Â  Â â”‚ Â  - Dashboard Â  Â  Â  Â  Â  Â  Â  Â  Â  â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  â”‚

â”‚ Â - Logo Â  Â â”‚ Â  - Products list Â  Â  Â  Â  Â  Â  Â  â”‚ Â  - Messages Â  Â  Â â”‚

â”‚ Â - Nav Â  Â  â”‚ Â  - Product detail Â  Â  Â  Â  Â  Â  Â â”‚ Â  - Input Â  Â  Â  Â  â”‚

â”‚ Â - Links Â  â”‚ Â  - Alerts Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â â”‚ Â  - Quick actions â”‚

â”‚ Â  Â  Â  Â  Â  Â â”‚ Â  - Schedules Â  Â  Â  Â  Â  Â  Â  Â  Â  â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  â”‚

â”‚ Â  Â  Â  Â  Â  Â â”‚ Â  - Stores Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  â”‚

â”‚ Â  Â  Â  Â  Â  Â â”‚ Â  - Settings Â  Â  Â  Â  Â  Â  Â  Â  Â  Â â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  â”‚

â”‚ Â  Â  Â  Â  Â  Â â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  â”‚

â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤

â”‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Footer (optional) Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

  

### 9.5 Layout Decisions

  

| Element | Decision | Details |

|---------|----------|---------|

| **Structure** | 3-column | Sidebar + Main + Chat Panel |

| **Sidebar** | Left side, collapsible | Dark periwinkle background, collapses on mobile/tablet |

| **Chat Panel** | Right side, collapsible | Accessible from any page via toggle button |

| **Chat Default** | Expanded on desktop | Expanded â‰¥1280px, collapsed on smaller screens |

| **Responsive** | Mobile-first | Sidebar and chat collapse to overlays on mobile |

  

### 9.6 Theme

  

| Setting | Choice |

|---------|--------|

| **Color Palette** | Soft Periwinkle |

| **Dark Mode** | Yes - toggle in settings |

| **Default Theme** | System preference on first visit |

| **Persistence** | localStorage |

  

**Soft Periwinkle Palette (Tailwind-ready):**

  

```javascript

// tailwind.config.js

{

Â  "soft-periwinkle": {

Â  Â  "50": "#edecf8",

Â  Â  "100": "#dbdaf1",

Â  Â  "200": "#b7b5e3",

Â  Â  "300": "#938fd6",

Â  Â  "400": "#6f6ac8",

Â  Â  "500": "#4b45ba",

Â  Â  "600": "#3c3795",

Â  Â  "700": "#2d2970",

Â  Â  "800": "#1e1c4a",

Â  Â  "900": "#0f0e25",

Â  Â  "950": "#0a0a1a"

Â  }

}

```

  

**Semantic Colors:**

  

| Purpose | Light Mode | Dark Mode |

|---------|------------|-----------|

| Primary accent | periwinkle-500 | periwinkle-400 |

| Sidebar background | periwinkle-100 | periwinkle-950 |

| Price drop (good) | green-600 | green-500 |

| Price rise (bad) | red-600 | red-500 |

| Status healthy | green-600 | green-500 |

| Status degraded | amber-600 | amber-500 |

| Status error | red-600 | red-500 |

  

### 9.7 Pages

  

| Page | Route | Purpose |

|------|-------|---------|

| **Dashboard** | `/` | Overview: recent products, biggest drops, quick stats |

| **Products** | `/products` | List all tracked products with filters |

| **Product Detail** | `/products/:id` | Price history chart, alerts, schedule settings |

| **Alerts** | `/alerts` | Manage all alerts, notification history |

| **Schedules** | `/schedules` | Advanced schedule management |

| **Stores** | `/stores` | View supported stores, health status (read-only) |

| **Settings** | `/settings` | Theme toggle, system info, about |

| **Chat Panel** | (overlay) | AI agent conversation, accessible from any page |

  

### 9.8 Page Details

  

#### Dashboard (`/`)

  

| Section | Content |

|---------|---------|

| **Stats Cards** | Total products, active alerts, price drops today |

| **Recent Products** | Last 5 added products |

| **Biggest Drops** | Top 5 price drops (24h/7d) |

| **Quick Add** | URL input to quickly add product |

| **Store Health** | Summary of any failing stores |

  

#### Products (`/products`)

  

| Feature | Implementation |

|---------|----------------|

| **View Modes** | List / Grid toggle |

| **Filters** | Store, status, price range |

| **Sort** | Name, price, last checked, date added |

| **Search** | Search by name (via RAG) |

| **Bulk Actions** | Delete selected (with confirmation) |

| **Pagination** | Offset-based, 20 per page |

  

#### Product Detail (`/products/:id`)

  

| Section | Content |

|---------|---------|

| **Header** | Product image, name, store, current price |

| **Price Chart** | Recharts line chart (7d/30d/90d/all) |

| **Price Stats** | Lowest, highest, average, % change |

| **Alerts** | List alerts for this product, create new |

| **Schedule** | Current schedule, enable/disable, simple edit |

| **Actions** | Refresh now, remove product |

  

#### Alerts (`/alerts`)

  

| Section | Content |

|---------|---------|

| **Active Alerts** | List with product, type, target, status |

| **Create Alert** | Form: select product, type, target value |

| **Notification History** | Recent notifications sent |

| **Filters** | By product, by type, triggered/not |

  

#### Schedules (`/schedules`)

  

| Section | Content |

|---------|---------|

| **Product Schedules** | Custom schedules per product |

| **Store Schedules** | Store-wide schedules |

| **Default Schedule** | Display system default (6 AM Â±30min) |

| **Create Schedule** | Form: CRON builder, product/store selector |

| **Next Runs** | Preview upcoming scheduled checks |

  

#### Stores (`/stores`)

  

| Section | Content |

|---------|---------|

| **Store List** | All stores with domain, name |

| **Health Status** | Success rate, last success, failing products |

| **Whitelisted Badge** | Indicate P0/P1/P2 vs auto-added |

| **Filter** | Healthy/degraded/failing, whitelisted/all |

  

**Note:** Read-only for MVP. Store CRUD deferred to SaaS admin.

  

#### Settings (`/settings`)

  

| Section | Content |

|---------|---------|

| **Theme** | Light/Dark/System toggle |

| **System Info** | App version, uptime |

| **Stats** | Product count, store count, DB size |

| **About** | Perpee description, links |

  

**Note:** Notification preferences are in env vars for MVP. Full settings when moving to SaaS.

  

### 9.9 Chat Panel

  

#### Behavior

  

| Setting | Value |

|---------|-------|

| **Position** | Right side of screen |

| **Width** | 380px (fixed) |

| **Toggle** | Floating button when collapsed |

| **Default State** | Expanded on desktop (â‰¥1280px) |

| **Connection** | WebSocket to `/api/chat/ws` |

| **Persistence** | Messages cleared on page refresh (session-only) |

  

#### Features

  

| Feature | Implementation |

|---------|----------------|

| **Message Display** | User messages right, agent left |

| **Streaming** | Show response as it streams |

| **Thinking Indicator** | Animated dots while processing |

| **Tool Calls** | Show tool being called (collapsible) |

| **Quick Actions** | Preset buttons: "Check prices", "Show drops" |

| **Welcome Message** | Display on connect (from C1) |

  

#### Message Types Display

  

| Type | Display |

|------|---------|

| `thinking` | "Perpee is thinking..." with animation |

| `tool_call` | "ğŸ”§ Calling: scrape_product..." (collapsible) |

| `tool_result` | Hidden or collapsed by default |

| `response` | Normal message bubble |

| `error` | Red error message |

  

### 9.10 Responsive Breakpoints

  

| Breakpoint | Width | Layout Changes |

|------------|-------|----------------|

| **Mobile** | <768px | Sidebar hidden (hamburger), chat as full overlay |

| **Tablet** | 768-1023px | Sidebar collapsed, chat as overlay |

| **Desktop** | 1024-1279px | Sidebar expanded, chat collapsed |

| **Wide** | â‰¥1280px | Sidebar expanded, chat expanded |

  

### 9.11 Components

  

#### Layout Components

  

| Component | Purpose |

|-----------|---------|

| `Layout` | Main 3-column layout wrapper |

| `Sidebar` | Navigation sidebar |

| `ChatPanel` | Collapsible chat interface |

| `Header` | Optional top header |

| `PageHeader` | Page title + actions |

  

#### Shared Components

  

| Component | Purpose |

|-----------|---------|

| `ProductCard` | Product display (list/grid) |

| `PriceDisplay` | Formatted price with currency |

| `PriceChange` | Price change with color (green/red) |

| `PriceChart` | Recharts line chart |

| `AlertBadge` | Alert type + status indicator |

| `StoreBadge` | Store name with health indicator |

| `StatusBadge` | Generic status indicator |

| `ConfirmDialog` | Destructive action confirmation |

| `EmptyState` | No data placeholder |

| `LoadingState` | Loading spinner/skeleton |

| `ErrorState` | Error message with retry |

  

#### Form Components

  

| Component | Purpose |

|-----------|---------|

| `ProductForm` | Add product by URL |

| `AlertForm` | Create/edit alert |

| `ScheduleForm` | Create/edit schedule with CRON builder |

| `SearchInput` | Search with debounce |

| `FilterDropdown` | Filter selection |

  

### 9.12 API Integration

  

#### React Query Setup

  

```typescript

// lib/api.ts

import { QueryClient } from '@tanstack/react-query'

  

export const queryClient = new QueryClient({

Â  defaultOptions: {

Â  Â  queries: {

Â  Â  Â  staleTime: 30 * 1000, Â  Â  Â // 30 seconds

Â  Â  Â  refetchOnWindowFocus: true,

Â  Â  Â  retry: 1,

Â  Â  },

Â  },

})

```

  

#### API Client

  

```typescript

// lib/api-client.ts

const API_BASE = '/api'

  

export const api = {

Â  products: {

Â  Â  list: (params) => fetch(`${API_BASE}/products?${new URLSearchParams(params)}`),

Â  Â  get: (id) => fetch(`${API_BASE}/products/${id}`),

Â  Â  create: (data) => fetch(`${API_BASE}/products`, { method: 'POST', body: JSON.stringify(data) }),

Â  Â  delete: (id) => fetch(`${API_BASE}/products/${id}`, { method: 'DELETE' }),

Â  Â  refresh: (id) => fetch(`${API_BASE}/products/${id}/refresh`, { method: 'POST' }),

Â  Â  history: (id) => fetch(`${API_BASE}/products/${id}/history`),

Â  },

Â  alerts: { /* similar */ },

Â  schedules: { /* similar */ },

Â  stores: { /* similar */ },

}

```

  

#### WebSocket Hook

  

```typescript

// hooks/useChat.ts

export function useChat() {

Â  const [messages, setMessages] = useState<Message[]>([])

Â  const [isConnected, setIsConnected] = useState(false)

Â  const ws = useRef<WebSocket | null>(null)

  

Â  useEffect(() => {

Â  Â  ws.current = new WebSocket(`ws://${window.location.host}/api/chat/ws`)

Â  Â  ws.current.onopen = () => setIsConnected(true)

Â  Â  ws.current.onclose = () => setIsConnected(false)

Â  Â  ws.current.onmessage = (event) => {

Â  Â  Â  const data = JSON.parse(event.data)

Â  Â  Â  // Handle different message types

Â  Â  }

Â  Â  return () => ws.current?.close()

Â  }, [])

  

Â  const sendMessage = (content: string) => {

Â  Â  ws.current?.send(JSON.stringify({ message: content }))

Â  }

  

Â  return { messages, isConnected, sendMessage }

}

```

  

### 9.13 Security Considerations

  

| Risk | Severity | Mitigation |

|------|----------|------------|

| XSS from scraped content | HIGH | DOMPurify sanitization before render |

| XSS in product names | HIGH | React's default escaping + DOMPurify |

| Clickjacking | MEDIUM | X-Frame-Options header (backend) |

| CSRF | LOW | No auth = no CSRF risk for MVP |

| localStorage tampering | LOW | Theme only, no sensitive data |

  

#### DOMPurify Usage

  

```typescript

import DOMPurify from 'dompurify'

  

// Sanitize any scraped content before display

function ProductName({ name }: { name: string }) {

Â  return <span>{DOMPurify.sanitize(name)}</span>

}

```

  

### 9.14 File Structure

  

```

frontend/

â”œâ”€â”€ src/

â”‚ Â  â”œâ”€â”€ components/

â”‚ Â  â”‚ Â  â”œâ”€â”€ layout/

â”‚ Â  â”‚ Â  â”‚ Â  â”œâ”€â”€ Layout.tsx

â”‚ Â  â”‚ Â  â”‚ Â  â”œâ”€â”€ Sidebar.tsx

â”‚ Â  â”‚ Â  â”‚ Â  â”œâ”€â”€ ChatPanel.tsx

â”‚ Â  â”‚ Â  â”‚ Â  â””â”€â”€ PageHeader.tsx

â”‚ Â  â”‚ Â  â”œâ”€â”€ products/

â”‚ Â  â”‚ Â  â”‚ Â  â”œâ”€â”€ ProductCard.tsx

â”‚ Â  â”‚ Â  â”‚ Â  â”œâ”€â”€ ProductList.tsx

â”‚ Â  â”‚ Â  â”‚ Â  â”œâ”€â”€ ProductForm.tsx

â”‚ Â  â”‚ Â  â”‚ Â  â””â”€â”€ PriceChart.tsx

â”‚ Â  â”‚ Â  â”œâ”€â”€ alerts/

â”‚ Â  â”‚ Â  â”‚ Â  â”œâ”€â”€ AlertCard.tsx

â”‚ Â  â”‚ Â  â”‚ Â  â”œâ”€â”€ AlertList.tsx

â”‚ Â  â”‚ Â  â”‚ Â  â””â”€â”€ AlertForm.tsx

â”‚ Â  â”‚ Â  â”œâ”€â”€ schedules/

â”‚ Â  â”‚ Â  â”‚ Â  â”œâ”€â”€ ScheduleCard.tsx

â”‚ Â  â”‚ Â  â”‚ Â  â”œâ”€â”€ ScheduleList.tsx

â”‚ Â  â”‚ Â  â”‚ Â  â””â”€â”€ ScheduleForm.tsx

â”‚ Â  â”‚ Â  â”œâ”€â”€ stores/

â”‚ Â  â”‚ Â  â”‚ Â  â”œâ”€â”€ StoreCard.tsx

â”‚ Â  â”‚ Â  â”‚ Â  â””â”€â”€ StoreList.tsx

â”‚ Â  â”‚ Â  â”œâ”€â”€ chat/

â”‚ Â  â”‚ Â  â”‚ Â  â”œâ”€â”€ MessageBubble.tsx

â”‚ Â  â”‚ Â  â”‚ Â  â”œâ”€â”€ ChatInput.tsx

â”‚ Â  â”‚ Â  â”‚ Â  â””â”€â”€ QuickActions.tsx

â”‚ Â  â”‚ Â  â””â”€â”€ ui/ Â  Â  Â  Â  Â  Â  Â  Â  # shadcn components

â”‚ Â  â”‚ Â  Â  Â  â”œâ”€â”€ button.tsx

â”‚ Â  â”‚ Â  Â  Â  â”œâ”€â”€ card.tsx

â”‚ Â  â”‚ Â  Â  Â  â”œâ”€â”€ input.tsx

â”‚ Â  â”‚ Â  Â  Â  â””â”€â”€ ...

â”‚ Â  â”œâ”€â”€ pages/

â”‚ Â  â”‚ Â  â”œâ”€â”€ Dashboard.tsx

â”‚ Â  â”‚ Â  â”œâ”€â”€ Products.tsx

â”‚ Â  â”‚ Â  â”œâ”€â”€ ProductDetail.tsx

â”‚ Â  â”‚ Â  â”œâ”€â”€ Alerts.tsx

â”‚ Â  â”‚ Â  â”œâ”€â”€ Schedules.tsx

â”‚ Â  â”‚ Â  â”œâ”€â”€ Stores.tsx

â”‚ Â  â”‚ Â  â””â”€â”€ Settings.tsx

â”‚ Â  â”œâ”€â”€ hooks/

â”‚ Â  â”‚ Â  â”œâ”€â”€ useChat.ts

â”‚ Â  â”‚ Â  â”œâ”€â”€ useProducts.ts

â”‚ Â  â”‚ Â  â”œâ”€â”€ useAlerts.ts

â”‚ Â  â”‚ Â  â””â”€â”€ useTheme.ts

â”‚ Â  â”œâ”€â”€ lib/

â”‚ Â  â”‚ Â  â”œâ”€â”€ api.ts Â  Â  Â  Â  Â  Â  Â # React Query client

â”‚ Â  â”‚ Â  â”œâ”€â”€ api-client.ts Â  Â  Â  # Fetch wrapper

â”‚ Â  â”‚ Â  â”œâ”€â”€ utils.ts Â  Â  Â  Â  Â  Â # Helpers

â”‚ Â  â”‚ Â  â””â”€â”€ constants.ts

â”‚ Â  â”œâ”€â”€ App.tsx

â”‚ Â  â”œâ”€â”€ main.tsx

â”‚ Â  â””â”€â”€ index.css Â  Â  Â  Â  Â  Â  Â  # Tailwind imports

â”œâ”€â”€ public/

â”œâ”€â”€ index.html

â”œâ”€â”€ package.json

â”œâ”€â”€ vite.config.ts

â”œâ”€â”€ tailwind.config.js

â””â”€â”€ tsconfig.json

```

  

### 9.15 Cross-Component Dependencies

  

| Component | Dependency |

|-----------|------------|

| Component 8 (API) | All REST endpoints + WebSocket |

| Component 7 (Notifications) | Notification history display |

| Component 6 (Scheduler) | Schedule display and creation |

| Component 5 (Self-Healing) | Store health status display |

| Component 4 (RAG) | Product search via chat |

| Component 1 (Agent) | Chat panel connects to agent |

  

---

  

## Implementation Phases

  

### Phase 1: Foundation (Week 1-2)

- [ ] Project structure setup

- [ ] Docker configuration

- [ ] SQLite + SQLModel setup

- [ ] Basic FastAPI skeleton

- [ ] Settings/config management

  

### Phase 2: Scraper Engine (Week 2-3)

- [ ] Crawl4AI integration

- [ ] Extraction strategies (JSON-LD, CSS, LLM)

- [ ] Store configurations

- [ ] Selector storage

  

### Phase 3: Database & Models (Week 3-4)

- [ ] All SQLModel models

- [ ] CRUD operations

- [ ] Price history tracking

  

### Phase 4: Agent Core (Week 4-5)

- [ ] Pydantic AI setup

- [ ] OpenRouter integration

- [ ] Tool definitions

- [ ] Guardrails implementation

  

### Phase 5: RAG System (Week 5-6)

- [ ] ChromaDB setup

- [ ] Embedding pipeline

- [ ] Hybrid search

  

### Phase 6: Self-Healing (Week 6-7)

- [ ] Failure detection

- [ ] Recovery strategies

- [ ] Health tracking

  

### Phase 7: Scheduler (Week 7-8)

- [ ] APScheduler integration

- [ ] CRON management

- [ ] Batch optimization

  

### Phase 8: Notifications (Week 8-9)

- [ ] Email (Resend)


- [ ] Alert rules

  

### Phase 9: API Endpoints (Week 9-10)

- [ ] REST endpoints

- [ ] WebSocket chat

- [ ] Error handling

  

### Phase 10: Web UI (Week 10-12)

- [ ] React setup

- [ ] All pages & components

- [ ] API integration

  

### Phase 11: Testing & Deployment (Week 12-13)

- [ ] Testing

- [ ] Oracle Cloud deployment

- [ ] Documentation

  

---

  

## Appendix A: Supported Stores (Initial Whitelist)

  

### P0 - MVP Launch (16 stores)

  

| Category | Store | Domain |

|----------|-------|--------|

| **General** | Amazon Canada | amazon.ca |

| **General** | Walmart Canada | walmart.ca |

| **General** | Costco Canada | costco.ca |

| **General** | Canadian Tire | canadiantire.ca |

| **Electronics** | Best Buy Canada | bestbuy.ca |

| **Electronics** | The Source | thesource.ca |

| **Electronics** | Memory Express | memoryexpress.com |

| **Electronics** | Canada Computers | canadacomputers.com |

| **Electronics** | Newegg Canada | newegg.ca |

| **Grocery** | Loblaws | loblaws.ca |

| **Grocery** | No Frills | nofrills.ca |

| **Grocery** | Real Canadian Superstore | realcanadiansuperstore.ca |

| **Grocery** | Metro | metro.ca |

| **Grocery** | Sobeys | sobeys.com |

| **Pharmacy** | Shoppers Drug Mart | shoppersdrugmart.ca |

| **Home** | Home Depot Canada | homedepot.ca |

  

### P1 - Post-MVP Phase 1 (15 stores)

  

| Category | Store | Domain |

|----------|-------|--------|

| **Grocery** | FreshCo | freshco.com |

| **Grocery** | Safeway Canada | safeway.ca |

| **Grocery** | Save-On-Foods | saveonfoods.com |

| **Grocery** | Food Basics | foodbasics.ca |

| **Grocery** | T&T Supermarket | tnt-supermarket.com |

| **Pharmacy** | London Drugs | londondrugs.com |

| **Pharmacy** | Rexall | rexall.ca |

| **Electronics** | Visions Electronics | visions.ca |

| **Home** | IKEA Canada | ikea.com/ca |

| **Home** | Lowe's Canada | lowes.ca |

| **Home** | Rona | rona.ca |

| **Home** | The Brick | thebrick.com |

| **Sports** | Sport Chek | sportchek.ca |

| **Sports** | MEC | mec.ca |

| **Sports** | Decathlon Canada | decathlon.ca |

  

### P2 - Post-MVP Phase 2 (17 stores)

  

| Category | Store | Domain |

|----------|-------|--------|

| **Grocery** | VoilÃ  (Sobeys) | voila.ca |

| **Grocery** | PC Express | pcexpress.ca |

| **Pharmacy** | Jean Coutu | jeancoutu.com |

| **Home** | Wayfair Canada | wayfair.ca |

| **Home** | Structube | structube.com |

| **Home** | Leon's | leons.ca |

| **Sports** | Atmosphere | atmosphere.ca |

| **Sports** | Sporting Life | sportinglife.ca |

| **Fashion** | Hudson's Bay | thebay.com |

| **Fashion** | Simons | simons.ca |

| **Fashion** | Aritzia | aritzia.com |

| **Fashion** | Mark's | marks.com |

| **Pets** | PetSmart Canada | petsmart.ca |

| **Pets** | Pet Valu | petvalu.com |

| **Other** | Staples Canada | staples.ca |

| **Other** | Indigo/Chapters | indigo.ca |

| **Other** | Well.ca | well.ca |

  

### Store Addition Policy

- **Whitelisted stores:** P0/P1/P2 stores work immediately with pre-configured selectors
- **New stores:** Must use `scan_website` tool first to validate safety and feasibility
- **After scan:** If feasible, store is added to whitelist with learned selectors
- **User requests:** P2 stores can be prioritized based on demand

---

## Appendix B: Cost Breakdown

| Component | Monthly | Yearly |
|-----------|---------|--------|
| Hosting (Oracle Free) | $0 | $0 |
| Database (SQLite) | $0 | $0 |
| Vector DB (ChromaDB) | $0 | $0 |
| LLM (OpenRouter free tier) | ~$0.50 | ~$5 |
| Embeddings (OpenAI) | ~$0.10 | ~$1-2 |
| Email (Resend free tier) | $0 | $0 |
| **Total** | **~$0.60** | **~$7** |

---

## Appendix C: Component Dependencies

This dependency graph shows the implementation order for Claude Code:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Implementation Order                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Phase 1: Foundation                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚  â”‚ C1: Project  â”‚â”€â”€â”€â”€â–ºâ”‚ C2: Database â”‚                          â”‚
â”‚  â”‚   Structure  â”‚     â”‚    Schema    â”‚                          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                              â”‚                                   â”‚
â”‚  Phase 2: Core Engine        â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚  â”‚ C3: Scraper  â”‚â—„â”€â”€â”€â”€â”‚ C4: RAG      â”‚                          â”‚
â”‚  â”‚    Engine    â”‚     â”‚   System     â”‚                          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚         â”‚                                                        â”‚
â”‚  Phase 3: Automation  â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚  â”‚ C5: Self-    â”‚â—„â”€â”€â”€â”€â”‚ C6: Schedulerâ”‚                          â”‚
â”‚  â”‚    Healing   â”‚     â”‚              â”‚                          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚         â”‚                                                        â”‚
â”‚  Phase 4: Communication                                          â”‚
â”‚         â–¼                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ C7: Notif.   â”‚â”€â”€â”€â”€â–ºâ”‚ C8: API      â”‚â”€â”€â”€â”€â–ºâ”‚ C9: Web UI   â”‚     â”‚
â”‚  â”‚              â”‚     â”‚              â”‚     â”‚              â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Dependency Matrix

| Component | Depends On | Provides To |
|-----------|------------|-------------|
| C1: Project Structure | - | All components |
| C2: Database | C1 | C3, C4, C5, C6, C7, C8 |
| C3: Scraper | C1, C2 | C4, C5, C6 |
| C4: RAG | C1, C2, C3 | C1 (Agent), C8 |
| C5: Self-Healing | C2, C3 | C6, C7 |
| C6: Scheduler | C2, C3, C5 | C7 |
| C7: Notifications | C2, C5, C6 | C8 |
| C8: API | C1, C2, C4, C5, C6, C7 | C9 |
| C9: Web UI | C8 | - |

### Quick Implementation Checklist

- [ ] **Week 1-2:** C1 (Project Structure) + C2 (Database)
- [ ] **Week 2-3:** C3 (Scraper Engine)
- [ ] **Week 3-4:** C4 (RAG System)
- [ ] **Week 4-5:** C1 (Agent Core - tools integration)
- [ ] **Week 5-6:** C5 (Self-Healing)
- [ ] **Week 6-7:** C6 (Scheduler)
- [ ] **Week 7-8:** C7 (Notifications)
- [ ] **Week 8-9:** C8 (API Endpoints)
- [ ] **Week 9-11:** C9 (Web UI)
- [ ] **Week 11-12:** Integration Testing + Deployment

## Implementation Phases

  

### Phase 1: Foundation (Week 1-2)

- [ ] Project structure setup

- [ ] Docker configuration

- [ ] SQLite + SQLModel setup

- [ ] Basic FastAPI skeleton

- [ ] Settings/config management

  

### Phase 2: Scraper Engine (Week 2-3)

- [ ] Crawl4AI integration

- [ ] Extraction strategies (JSON-LD, CSS, LLM)

- [ ] Store configurations

- [ ] Selector storage

  

### Phase 3: Database & Models (Week 3-4)

- [ ] All SQLModel models

- [ ] CRUD operations

- [ ] Price history tracking

  

### Phase 4: Agent Core (Week 4-5)

- [ ] Pydantic AI setup

- [ ] OpenRouter integration

- [ ] Tool definitions

- [ ] Guardrails implementation

  

### Phase 5: RAG System (Week 5-6)

- [ ] ChromaDB setup

- [ ] Embedding pipeline

- [ ] Hybrid search

  

### Phase 6: Self-Healing (Week 6-7)

- [ ] Failure detection

- [ ] Recovery strategies

- [ ] Health tracking

  

### Phase 7: Scheduler (Week 7-8)

- [ ] APScheduler integration

- [ ] CRON management

- [ ] Batch optimization

  

### Phase 8: Notifications (Week 8-9)

- [ ] Email (Resend)


- [ ] Alert rules

  

### Phase 9: API Endpoints (Week 9-10)

- [ ] REST endpoints

- [ ] WebSocket chat

- [ ] Error handling

  

### Phase 10: Web UI (Week 10-12)

- [ ] React setup

- [ ] All pages & components

- [ ] API integration

  

### Phase 11: Testing & Deployment (Week 12-13)

- [ ] Testing

- [ ] Oracle Cloud deployment

- [ ] Documentation

  

---

  

## Appendix A: Supported Stores (Initial Whitelist)

  

### P0 - MVP Launch (16 stores)

  

| Category | Store | Domain |

|----------|-------|--------|

| **General** | Amazon Canada | amazon.ca |

| **General** | Walmart Canada | walmart.ca |

| **General** | Costco Canada | costco.ca |

| **General** | Canadian Tire | canadiantire.ca |

| **Electronics** | Best Buy Canada | bestbuy.ca |

| **Electronics** | The Source | thesource.ca |

| **Electronics** | Memory Express | memoryexpress.com |

| **Electronics** | Canada Computers | canadacomputers.com |

| **Electronics** | Newegg Canada | newegg.ca |

| **Grocery** | Loblaws | loblaws.ca |

| **Grocery** | No Frills | nofrills.ca |

| **Grocery** | Real Canadian Superstore | realcanadiansuperstore.ca |

| **Grocery** | Metro | metro.ca |

| **Grocery** | Sobeys | sobeys.com |

| **Pharmacy** | Shoppers Drug Mart | shoppersdrugmart.ca |

| **Home** | Home Depot Canada | homedepot.ca |

  

### P1 - Post-MVP Phase 1 (15 stores)

  

| Category | Store | Domain |

|----------|-------|--------|

| **Grocery** | FreshCo | freshco.com |

| **Grocery** | Safeway Canada | safeway.ca |

| **Grocery** | Save-On-Foods | saveonfoods.com |

| **Grocery** | Food Basics | foodbasics.ca |

| **Grocery** | T&T Supermarket | tnt-supermarket.com |

| **Pharmacy** | London Drugs | londondrugs.com |

| **Pharmacy** | Rexall | rexall.ca |

| **Electronics** | Visions Electronics | visions.ca |

| **Home** | IKEA Canada | ikea.com/ca |

| **Home** | Lowe's Canada | lowes.ca |

| **Home** | Rona | rona.ca |

| **Home** | The Brick | thebrick.com |

| **Sports** | Sport Chek | sportchek.ca |

| **Sports** | MEC | mec.ca |

| **Sports** | Decathlon Canada | decathlon.ca |

  

### P2 - Post-MVP Phase 2 (17 stores)

  

| Category | Store | Domain |

|----------|-------|--------|

| **Grocery** | VoilÃ  (Sobeys) | voila.ca |

| **Grocery** | PC Express | pcexpress.ca |

| **Pharmacy** | Jean Coutu | jeancoutu.com |

| **Home** | Wayfair Canada | wayfair.ca |

| **Home** | Structube | structube.com |

| **Home** | Leon's | leons.ca |

| **Sports** | Atmosphere | atmosphere.ca |

| **Sports** | Sporting Life | sportinglife.ca |

| **Fashion** | Hudson's Bay | thebay.com |

| **Fashion** | Simons | simons.ca |

| **Fashion** | Aritzia | aritzia.com |

| **Fashion** | Mark's | marks.com |

| **Pets** | PetSmart Canada | petsmart.ca |

| **Pets** | Pet Valu | petvalu.com |

| **Other** | Staples Canada | staples.ca |

| **Other** | Indigo/Chapters | indigo.ca |

| **Other** | Well.ca | well.ca |

  

### Store Addition Policy

- **Whitelisted stores:** P0/P1/P2 stores work immediately with pre-configured selectors
- **New stores:** Must use `scan_website` tool first to validate safety and feasibility
- **After scan:** If feasible, store is added to whitelist with learned selectors
- **User requests:** P2 stores can be prioritized based on demand

---

## Appendix B: Cost Breakdown

| Component | Monthly | Yearly |
|-----------|---------|--------|
| Hosting (Oracle Free) | $0 | $0 |
| Database (SQLite) | $0 | $0 |
| Vector DB (ChromaDB) | $0 | $0 |
| LLM (OpenRouter free tier) | ~$0.50 | ~$5 |
| Embeddings (OpenAI) | ~$0.10 | ~$1-2 |
| Email (Resend free tier) | $0 | $0 |
| **Total** | **~$0.60** | **~$7** |

---

## Appendix C: Component Dependencies

This dependency graph shows the implementation order for Claude Code:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Implementation Order                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Phase 1: Foundation                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚  â”‚ C1: Project  â”‚â”€â”€â”€â”€â–ºâ”‚ C2: Database â”‚                          â”‚
â”‚  â”‚   Structure  â”‚     â”‚    Schema    â”‚                          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                              â”‚                                   â”‚
â”‚  Phase 2: Core Engine        â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚  â”‚ C3: Scraper  â”‚â—„â”€â”€â”€â”€â”‚ C4: RAG      â”‚                          â”‚
â”‚  â”‚    Engine    â”‚     â”‚   System     â”‚                          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚         â”‚                                                        â”‚
â”‚  Phase 3: Automation  â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚  â”‚ C5: Self-    â”‚â—„â”€â”€â”€â”€â”‚ C6: Schedulerâ”‚                          â”‚
â”‚  â”‚    Healing   â”‚     â”‚              â”‚                          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚         â”‚                                                        â”‚
â”‚  Phase 4: Communication                                          â”‚
â”‚         â–¼                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ C7: Notif.   â”‚â”€â”€â”€â”€â–ºâ”‚ C8: API      â”‚â”€â”€â”€â”€â–ºâ”‚ C9: Web UI   â”‚     â”‚
â”‚  â”‚              â”‚     â”‚              â”‚     â”‚              â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Dependency Matrix

| Component | Depends On | Provides To |
|-----------|------------|-------------|
| C1: Project Structure | - | All components |
| C2: Database | C1 | C3, C4, C5, C6, C7, C8 |
| C3: Scraper | C1, C2 | C4, C5, C6 |
| C4: RAG | C1, C2, C3 | C1 (Agent), C8 |
| C5: Self-Healing | C2, C3 | C6, C7 |
| C6: Scheduler | C2, C3, C5 | C7 |
| C7: Notifications | C2, C5, C6 | C8 |
| C8: API | C1, C2, C4, C5, C6, C7 | C9 |
| C9: Web UI | C8 | - |

### Quick Implementation Checklist

- [ ] **Week 1-2:** C1 (Project Structure) + C2 (Database)
- [ ] **Week 2-3:** C3 (Scraper Engine)
- [ ] **Week 3-4:** C4 (RAG System)
- [ ] **Week 4-5:** C1 (Agent Core - tools integration)
- [ ] **Week 5-6:** C5 (Self-Healing)
- [ ] **Week 6-7:** C6 (Scheduler)
- [ ] **Week 7-8:** C7 (Notifications)
- [ ] **Week 8-9:** C8 (API Endpoints)
- [ ] **Week 9-11:** C9 (Web UI)
- [ ] **Week 11-12:** Integration Testing + Deployment

## Appendix A: Supported Stores (Initial Whitelist)

  

### P0 - MVP Launch (16 stores)

  

| Category | Store | Domain |

|----------|-------|--------|

| **General** | Amazon Canada | amazon.ca |

| **General** | Walmart Canada | walmart.ca |

| **General** | Costco Canada | costco.ca |

| **General** | Canadian Tire | canadiantire.ca |

| **Electronics** | Best Buy Canada | bestbuy.ca |

| **Electronics** | The Source | thesource.ca |

| **Electronics** | Memory Express | memoryexpress.com |

| **Electronics** | Canada Computers | canadacomputers.com |

| **Electronics** | Newegg Canada | newegg.ca |

| **Grocery** | Loblaws | loblaws.ca |

| **Grocery** | No Frills | nofrills.ca |

| **Grocery** | Real Canadian Superstore | realcanadiansuperstore.ca |

| **Grocery** | Metro | metro.ca |

| **Grocery** | Sobeys | sobeys.com |

| **Pharmacy** | Shoppers Drug Mart | shoppersdrugmart.ca |

| **Home** | Home Depot Canada | homedepot.ca |

  

### P1 - Post-MVP Phase 1 (15 stores)

  

| Category | Store | Domain |

|----------|-------|--------|

| **Grocery** | FreshCo | freshco.com |

| **Grocery** | Safeway Canada | safeway.ca |

| **Grocery** | Save-On-Foods | saveonfoods.com |

| **Grocery** | Food Basics | foodbasics.ca |

| **Grocery** | T&T Supermarket | tnt-supermarket.com |

| **Pharmacy** | London Drugs | londondrugs.com |

| **Pharmacy** | Rexall | rexall.ca |

| **Electronics** | Visions Electronics | visions.ca |

| **Home** | IKEA Canada | ikea.com/ca |

| **Home** | Lowe's Canada | lowes.ca |

| **Home** | Rona | rona.ca |

| **Home** | The Brick | thebrick.com |

| **Sports** | Sport Chek | sportchek.ca |

| **Sports** | MEC | mec.ca |

| **Sports** | Decathlon Canada | decathlon.ca |

  

### P2 - Post-MVP Phase 2 (17 stores)

  

| Category | Store | Domain |

|----------|-------|--------|

| **Grocery** | VoilÃ  (Sobeys) | voila.ca |

| **Grocery** | PC Express | pcexpress.ca |

| **Pharmacy** | Jean Coutu | jeancoutu.com |

| **Home** | Wayfair Canada | wayfair.ca |

| **Home** | Structube | structube.com |

| **Home** | Leon's | leons.ca |

| **Sports** | Atmosphere | atmosphere.ca |

| **Sports** | Sporting Life | sportinglife.ca |

| **Fashion** | Hudson's Bay | thebay.com |

| **Fashion** | Simons | simons.ca |

| **Fashion** | Aritzia | aritzia.com |

| **Fashion** | Mark's | marks.com |

| **Pets** | PetSmart Canada | petsmart.ca |

| **Pets** | Pet Valu | petvalu.com |

| **Other** | Staples Canada | staples.ca |

| **Other** | Indigo/Chapters | indigo.ca |

| **Other** | Well.ca | well.ca |

  

### Store Addition Policy

- **Whitelisted stores:** P0/P1/P2 stores work immediately with pre-configured selectors
- **New stores:** Must use `scan_website` tool first to validate safety and feasibility
- **After scan:** If feasible, store is added to whitelist with learned selectors
- **User requests:** P2 stores can be prioritized based on demand

---

## Appendix B: Cost Breakdown

| Component | Monthly | Yearly |
|-----------|---------|--------|
| Hosting (Oracle Free) | $0 | $0 |
| Database (SQLite) | $0 | $0 |
| Vector DB (ChromaDB) | $0 | $0 |
| LLM (OpenRouter free tier) | ~$0.50 | ~$5 |
| Embeddings (OpenAI) | ~$0.10 | ~$1-2 |
| Email (Resend free tier) | $0 | $0 |
| **Total** | **~$0.60** | **~$7** |

---

## Appendix C: Component Dependencies

This dependency graph shows the implementation order for Claude Code:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Implementation Order                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Phase 1: Foundation                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚  â”‚ C1: Project  â”‚â”€â”€â”€â”€â–ºâ”‚ C2: Database â”‚                          â”‚
â”‚  â”‚   Structure  â”‚     â”‚    Schema    â”‚                          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                              â”‚                                   â”‚
â”‚  Phase 2: Core Engine        â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚  â”‚ C3: Scraper  â”‚â—„â”€â”€â”€â”€â”‚ C4: RAG      â”‚                          â”‚
â”‚  â”‚    Engine    â”‚     â”‚   System     â”‚                          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚         â”‚                                                        â”‚
â”‚  Phase 3: Automation  â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚  â”‚ C5: Self-    â”‚â—„â”€â”€â”€â”€â”‚ C6: Schedulerâ”‚                          â”‚
â”‚  â”‚    Healing   â”‚     â”‚              â”‚                          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚         â”‚                                                        â”‚
â”‚  Phase 4: Communication                                          â”‚
â”‚         â–¼                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ C7: Notif.   â”‚â”€â”€â”€â”€â–ºâ”‚ C8: API      â”‚â”€â”€â”€â”€â–ºâ”‚ C9: Web UI   â”‚     â”‚
â”‚  â”‚              â”‚     â”‚              â”‚     â”‚              â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Dependency Matrix

| Component | Depends On | Provides To |
|-----------|------------|-------------|
| C1: Project Structure | - | All components |
| C2: Database | C1 | C3, C4, C5, C6, C7, C8 |
| C3: Scraper | C1, C2 | C4, C5, C6 |
| C4: RAG | C1, C2, C3 | C1 (Agent), C8 |
| C5: Self-Healing | C2, C3 | C6, C7 |
| C6: Scheduler | C2, C3, C5 | C7 |
| C7: Notifications | C2, C5, C6 | C8 |
| C8: API | C1, C2, C4, C5, C6, C7 | C9 |
| C9: Web UI | C8 | - |

### Quick Implementation Checklist

- [ ] **Week 1-2:** C1 (Project Structure) + C2 (Database)
- [ ] **Week 2-3:** C3 (Scraper Engine)
- [ ] **Week 3-4:** C4 (RAG System)
- [ ] **Week 4-5:** C1 (Agent Core - tools integration)
- [ ] **Week 5-6:** C5 (Self-Healing)
- [ ] **Week 6-7:** C6 (Scheduler)
- [ ] **Week 7-8:** C7 (Notifications)
- [ ] **Week 8-9:** C8 (API Endpoints)
- [ ] **Week 9-11:** C9 (Web UI)
- [ ] **Week 11-12:** Integration Testing + Deployment


---

## Appendix D: Component Dependencies

### Implementation Order

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Implementation Order                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Phase 1: Foundation                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚  â”‚ C1: Project  â”‚â”€â”€â”€â”€â–ºâ”‚ C2: Database â”‚                          â”‚
â”‚  â”‚   Structure  â”‚     â”‚    Schema    â”‚                          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                              â”‚                                   â”‚
â”‚  Phase 2: Core Engine        â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚  â”‚ C3: Scraper  â”‚â—„â”€â”€â”€â”€â”‚ C4: RAG      â”‚                          â”‚
â”‚  â”‚    Engine    â”‚     â”‚   System     â”‚                          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚         â”‚                                                        â”‚
â”‚  Phase 3: Automation  â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚  â”‚ C5: Self-    â”‚â—„â”€â”€â”€â”€â”‚ C6: Schedulerâ”‚                          â”‚
â”‚  â”‚    Healing   â”‚     â”‚              â”‚                          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚         â”‚                                                        â”‚
â”‚  Phase 4: Communication                                          â”‚
â”‚         â–¼                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ C7: Notif.   â”‚â”€â”€â”€â”€â–ºâ”‚ C8: API      â”‚â”€â”€â”€â”€â–ºâ”‚ C9: Web UI   â”‚     â”‚
â”‚  â”‚              â”‚     â”‚              â”‚     â”‚              â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Dependency Matrix

| Component | Depends On | Provides To |
|-----------|------------|-------------|
| C1: Project Structure | - | All components |
| C2: Database | C1 | C3, C4, C5, C6, C7, C8 |
| C3: Scraper | C1, C2 | C4, C5, C6 |
| C4: RAG | C1, C2, C3 | C1 (Agent), C8 |
| C5: Self-Healing | C2, C3 | C6, C7 |
| C6: Scheduler | C2, C3, C5 | C7 |
| C7: Notifications | C2, C5, C6 | C8 |
| C8: API | C1, C2, C4, C5, C6, C7 | C9 |
| C9: Web UI | C8 | - |

### Implementation Checklist

- [ ] **Week 1-2:** C1 (Project Structure) + C2 (Database)
- [ ] **Week 2-3:** C3 (Scraper Engine)
- [ ] **Week 3-4:** C4 (RAG System)
- [ ] **Week 4-5:** C1 (Agent Core - tools integration)
- [ ] **Week 5-6:** C5 (Self-Healing)
- [ ] **Week 6-7:** C6 (Scheduler)
- [ ] **Week 7-8:** C7 (Notifications)
- [ ] **Week 8-9:** C8 (API Endpoints)
- [ ] **Week 9-11:** C9 (Web UI)
- [ ] **Week 11-12:** Integration Testing + Deployment

---

## Document History

| Version | Date | Changes |
|---------|------|---------|
| 1.0 | Jan 6, 2025 | Initial Technical Spec - split from combined PRD |

---

*This document defines HOW to build Perpee. See PRD.md for WHAT to build and WHY.*
